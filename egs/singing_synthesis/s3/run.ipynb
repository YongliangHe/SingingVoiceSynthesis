{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "sys.path.insert(0, '/home/yongliang/third_party/merlin/src')\n",
    "from io_funcs.binary_io import BinaryIOCollection\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list_of_dir(dir_path):\n",
    "    res = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "    res.sort()\n",
    "    return res\n",
    "\n",
    "def gen_file_list(dir_path, file_id_list, ext):\n",
    "    return [os.path.join(dir_path, f + '.' + ext) for f in file_id_list]\n",
    "\n",
    "def get_file_id_list(file_list):\n",
    "    return [os.path.splitext(os.path.basename(f))[0] for f in file_list]\n",
    "\n",
    "\n",
    "io_funcs = BinaryIOCollection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merlin_dir = '/home/yongliang/third_party/merlin'\n",
    "silence_pattern = ['*-pau+*', '*-sil+*']\n",
    "curr_dir = os.getcwd()\n",
    "# hardcoded\n",
    "nit_dir = os.path.join(curr_dir, 'nit')\n",
    "wav_dir = os.path.join(nit_dir, 'wav2')\n",
    "exp_dir = os.path.join(curr_dir, 'exp')\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "lab_dir = os.path.join(exp_dir, 'lab')\n",
    "orig_lab_file_list = get_file_list_of_dir(lab_dir)\n",
    "file_id_list = get_file_id_list(orig_lab_file_list)\n",
    "\n",
    "SPTK = {'VOPR': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/vopr', \n",
    "       'MGC2SP': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/mgc2sp', \n",
    "       'C2ACR': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/c2acr', \n",
    "       'FREQT': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/freqt', \n",
    "       'MC2B': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/mc2b', \n",
    "       'MLPG': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/mlpg', \n",
    "       'B2MC': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/b2mc', \n",
    "       'VSUM': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/vsum', \n",
    "       'MERGE': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/merge', \n",
    "       'SOPR': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/sopr', \n",
    "       'BCP': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/bcp', \n",
    "       'VSTAT': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/vstat', \n",
    "       'X2X': '/home/yongliang/third_party/merlin/tools/bin/SPTK-3.9/x2x'}\n",
    "WORLD = {'SYNTHESIS': '/home/yongliang/third_party/merlin/tools/bin/WORLD/synth', \n",
    "        'ANALYSIS': '/home/yongliang/third_party/merlin/tools/bin/WORLD/analysis'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_dir = os.path.join(exp_dir, 'hmm')\n",
    "full_dir = os.path.join(nit_dir, 'full')\n",
    "mono_dir = os.path.join(nit_dir, 'mono')\n",
    "phones = os.path.join(nit_dir, 'monophone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---make file_id_list.scp: /home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/hmm/file_id_list.scp\n",
      "---make copy.scp: /home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/hmm/config/copy.scp\n",
      "---mfcc extraction at: /home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/hmm/mfc\n",
      "------make copy.cfg: /home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/hmm/config/cfg\n",
      "------extracting mfcc features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e378c16dbf1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maligner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForcedAlignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maligner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maligner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_hmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maligner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/third_party/merlin/egs/singing_synthesis/s3/src/forced_alignment.py\u001b[0m in \u001b[0;36mprepare_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_copy_scp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mfcc_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_scp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/third_party/merlin/egs/singing_synthesis/s3/src/forced_alignment.py\u001b[0m in \u001b[0;36m_mfcc_extraction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------extracting mfcc features...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHCopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-S'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_scp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;31m# write a CFG for what we just built\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         open(self.cfg, 'w').write(\"\"\"TARGETRATE = 50000.0\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1659\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.forced_alignment import ForcedAlignment\n",
    "\n",
    "aligner = ForcedAlignment(hmm_dir, wav_dir, full_dir, mono_dir, phones, lab_dir)\n",
    "aligner.prepare_training()\n",
    "aligner.train_hmm(7, 32)\n",
    "aligner.align()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dir = os.path.join(exp_dir, 'feat')\n",
    "lf0_dir = os.path.join(feat_dir, 'lf0')\n",
    "bap_dir = os.path.join(feat_dir, 'bap')\n",
    "mgc_dir = os.path.join(feat_dir, 'mgc')\n",
    "sample_rate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nitech_jp_song070_f001_003\n",
      "Running REAPER f0 extraction...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5ad0752e0645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/third_party/merlin/egs/singing_synthesis/s3/src/feature_extraction.py\u001b[0m in \u001b[0;36mextract_feat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mwav_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_wav_filelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Featers are ready in: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nitech_jp_song070_f001_004\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_007\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_010\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_012\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_014\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_015\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_016\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_019\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_020\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_021\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_022\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_023\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_025\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_028\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_029\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_030\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_037\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_039\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_040\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_041\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_045\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_048\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_050\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_051\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_054\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_055\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_059\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_060\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_063\n",
      "Running REAPER f0 extraction...\n",
      "\n",
      "nitech_jp_song070_f001_070\n",
      "Running REAPER f0 extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from src.feature_extraction import FeatureExtractor\n",
    "feature_extractor = FeatureExtractor(wav_dir, sample_rate, feat_dir)\n",
    "feature_extractor.extract_feat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration model related\n",
    "\n",
    "# hardcoded\n",
    "dur_lab_dim = 368\n",
    "dur_cmp_dim = 5\n",
    "dur_train_file_number = 27\n",
    "dur_valid_file_number = 1\n",
    "dur_test_file_number = 1\n",
    "\n",
    "dur_mdl_dir = os.path.join(exp_dir, 'duration_model')\n",
    "if not os.path.exists(dur_mdl_dir):\n",
    "    os.makedirs(dur_mdl_dir)\n",
    "\n",
    "dur_tmp_dir = os.path.join(dur_mdl_dir, 'tmp')\n",
    "if not os.path.exists(dur_tmp_dir):\n",
    "    os.makedirs(dur_tmp_dir)\n",
    "    \n",
    "dur_inter_dir = os.path.join(dur_mdl_dir, 'inter')\n",
    "if not os.path.exists(dur_inter_dir):\n",
    "    os.makedirs(dur_inter_dir)\n",
    "\n",
    "dur_lab_dir = os.path.join(dur_inter_dir, 'lab_' + str(dur_lab_dim))\n",
    "if not os.path.exists(dur_lab_dir):\n",
    "    os.makedirs(dur_lab_dir)\n",
    "    \n",
    "dur_lab_no_silence_dir = os.path.join(dur_inter_dir, 'lab_no_silence_' + str(dur_lab_dim))\n",
    "if not os.path.exists(dur_lab_no_silence_dir):\n",
    "    os.makedirs(dur_lab_no_silence_dir)\n",
    "    \n",
    "dur_lab_no_silence_norm_dir = os.path.join(dur_inter_dir, 'lab_no_silence_norm_' + str(dur_lab_dim))\n",
    "if not os.path.exists(dur_lab_no_silence_norm_dir):\n",
    "    os.makedirs(dur_lab_no_silence_norm_dir)\n",
    "\n",
    "dur_dur_dir = os.path.join(dur_inter_dir, 'dur')\n",
    "if not os.path.exists(dur_dur_dir):\n",
    "    os.makedirs(dur_dur_dir)\n",
    "    \n",
    "dur_cmp_dir = os.path.join(dur_inter_dir, 'cmp_' + str(dur_cmp_dim))\n",
    "if not os.path.exists(dur_cmp_dir):\n",
    "    os.makedirs(dur_cmp_dir)\n",
    "    \n",
    "dur_cmp_no_silence_dir = os.path.join(dur_inter_dir, 'cmp_no_silence_' + str(dur_cmp_dim))\n",
    "if not os.path.exists(dur_cmp_no_silence_dir):\n",
    "    os.makedirs(dur_cmp_no_silence_dir)\n",
    "    \n",
    "dur_cmp_no_silence_norm_dir = os.path.join(dur_inter_dir, 'cmp_no_silence_norm_' + str(dur_cmp_dim))\n",
    "if not os.path.exists(dur_cmp_no_silence_norm_dir):\n",
    "    os.makedirs(dur_cmp_no_silence_norm_dir)\n",
    "    \n",
    "dur_variance_dir = os.path.join(dur_inter_dir, 'variance')\n",
    "if not os.path.exists(dur_variance_dir):\n",
    "    os.makedirs(dur_variance_dir)\n",
    "    \n",
    "dur_nn_mdl_dir = os.path.join(dur_mdl_dir, 'mdl')\n",
    "if not os.path.exists(dur_nn_mdl_dir):\n",
    "    os.makedirs(dur_nn_mdl_dir)\n",
    "    \n",
    "    \n",
    "\n",
    "dur_lab_norm_file = os.path.join(dur_inter_dir, 'lab_norm_' + str(dur_lab_dim) + '.dat')\n",
    "dur_cmp_norm_file = os.path.join(dur_inter_dir, 'cmp_norm_' + str(dur_cmp_dim) + '.dat')\n",
    "\n",
    "dur_dur_var_file = os.path.join(dur_variance_dir, 'dur')\n",
    "\n",
    "    \n",
    "dur_lab_file_list = gen_file_list(dur_lab_dir, file_id_list, 'labbin')\n",
    "dur_lab_no_silence_file_list = gen_file_list(dur_lab_no_silence_dir, file_id_list, 'labbin')\n",
    "dur_lab_no_silence_norm_file_list = gen_file_list(dur_lab_no_silence_norm_dir, file_id_list, 'labbin')\n",
    "dur_dur_file_list = gen_file_list(dur_dur_dir, file_id_list, 'dur')\n",
    "dur_cmp_file_list = gen_file_list(dur_cmp_dir, file_id_list, 'cmp')\n",
    "dur_cmp_no_silence_file_list = gen_file_list(dur_cmp_no_silence_dir, file_id_list, 'cmp')\n",
    "dur_cmp_no_silence_norm_file_list = gen_file_list(dur_cmp_no_silence_norm_dir, file_id_list, 'cmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction from label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_dir = os.path.join(curr_dir, 'ques')\n",
    "question = os.path.join(ques_dir, 'general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.label_normalisation import HTSLabelNormalisation\n",
    "dur_lab_normaliser = HTSLabelNormalisation(question, add_frame_features=False, subphone_feats='none')\n",
    "dur_lab_normaliser.perform_normalisation(orig_lab_file_list, dur_lab_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove silence phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.silence_remover import SilenceRemover\n",
    "dur_silence_remover = SilenceRemover(n_cmp=dur_lab_dim, silence_pattern=silence_pattern, remove_frame_features=False, subphone_feats='none')\n",
    "dur_silence_remover.remove_silence(dur_lab_file_list, orig_lab_file_list, dur_lab_no_silence_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "_, num_frame = io_funcs.load_binary_file_frame(dur_lab_file_list[2], 368)\n",
    "_, num_frame_nn = io_funcs.load_binary_file_frame(dur_lab_no_silence_file_list[2], 368)\n",
    "print(num_frame)\n",
    "print(num_frame_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0. ...  -1.  -1.  -1.]\n",
      " [  0.   0.   0. ...  -1.  -1.  -1.]\n",
      " [  0.   0.   0. ... 192.   0. 100.]\n",
      " ...\n",
      " [  0.   0.   0. ...  72.  57.  43.]\n",
      " [  0.   0.   0. ...  -1.  -1.  -1.]\n",
      " [  0.   0.   0. ...  -1.  -1.  -1.]]\n"
     ]
    }
   ],
   "source": [
    "tmp, _ = io_funcs.load_binary_file_frame(dur_lab_file_list[2], 368)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.min_max_norm import MinMaxNormalisation\n",
    "dur_min_max_normaliser = MinMaxNormalisation(feature_dimension=dur_lab_dim, min_value=0.01, max_value=0.99)\n",
    "dur_min_max_normaliser.find_min_max_values(dur_lab_no_silence_file_list[0: dur_train_file_number])\n",
    "dur_min_max_normaliser.normalise_data(dur_lab_no_silence_file_list, dur_lab_no_silence_norm_file_list)\n",
    "dur_label_min_vector = dur_min_max_normaliser.min_vector\n",
    "dur_label_max_vector = dur_min_max_normaliser.max_vector\n",
    "dur_label_norm_info = np.concatenate((dur_label_min_vector, dur_label_max_vector), axis=0)\n",
    "dur_label_norm_info = np.array(dur_label_norm_info, 'float32')\n",
    "fid = open(dur_lab_norm_file, 'wb')\n",
    "dur_label_norm_info.tofile(fid)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 368)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_label_norm_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute duration from label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_lab_normaliser.prepare_dur_data(orig_lab_file_list, dur_dur_file_list, feature_type='numerical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 5)\n",
      "151\n",
      "[[  1. 161.  34.  18.  22.]\n",
      " [  2.   2.   2.   1.   1.]\n",
      " [  2.   1.  66.   7.   3.]\n",
      " [  5.  10.   1.   1.  15.]\n",
      " [  2.   5.   2.   1.   1.]\n",
      " [  4.   1.  32.   4.   5.]\n",
      " [  6.   1.  27.  20.   1.]\n",
      " [  1.   6.   2.   1.   2.]\n",
      " [  1.  54.   1.   1.   2.]\n",
      " [ 10.   9.   4.   2.   4.]]\n"
     ]
    }
   ],
   "source": [
    "feat, num_frame = io_funcs.load_binary_file_frame(dur_dur_file_list[0], 5)\n",
    "print(feat.shape)\n",
    "print(num_frame)\n",
    "print(feat[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/duration_model/inter/dur/nitech_jp_song070_f001_007.dur'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_dur_file_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make output features for duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_win = [-0.5, 0.0, 0.5]\n",
    "acc_win = [1.0, -2.0, 1.0]\n",
    "\"\"\"\n",
    "\"in\" & \"out\" just mean before & after feature composition \n",
    "like if we compute dynamic features, dimensions of out will be 3 times of in\n",
    "not really mean in & out of the network \n",
    "\"\"\" \n",
    "dur_in_dimension_dict = {'dur': 5} \n",
    "dur_out_dimension_dict = {'dur': 5}\n",
    "dur_in_file_list_dict = {'dur': dur_dur_file_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.acoustic_composition import AcousticComposition\n",
    "dur_acoustic_worker = AcousticComposition(delta_win = delta_win, acc_win = acc_win)\n",
    "dur_acoustic_worker.prepare_nn_data(dur_in_file_list_dict, dur_cmp_file_list, dur_in_dimension_dict, dur_out_dimension_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 5)\n",
      "131\n",
      "[[ 13.  72. 166.   2.  54.]\n",
      " [  9.  47.   1.  54.  32.]\n",
      " [  1.  18.   4.   4.   4.]\n",
      " [  3. 100.   1.   2.   6.]\n",
      " [  4.   5.   3.   3.   3.]\n",
      " [  1.  32.   1.   1.   3.]\n",
      " [  5.   3.   2.   2.   3.]\n",
      " [  2.  26.   1.   5.   8.]\n",
      " [  2.   3.   3.   7.   6.]\n",
      " [  6.  77.  17.   5.   5.]]\n"
     ]
    }
   ],
   "source": [
    "feat, num_frame = io_funcs.load_binary_file_frame(dur_cmp_file_list[2], 5)\n",
    "print(feat.shape)\n",
    "print(num_frame)\n",
    "print(feat[0:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove silence phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_silence_remover = SilenceRemover(n_cmp = dur_cmp_dim, silence_pattern = silence_pattern, remove_frame_features = False, subphone_feats = 'none')\n",
    "dur_silence_remover.remove_silence(dur_cmp_file_list, orig_lab_file_list, dur_cmp_no_silence_file_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "_, num_frame = io_funcs.load_binary_file_frame(dur_cmp_file_list[2], 5)\n",
    "_, num_frame_nn = io_funcs.load_binary_file_frame(dur_cmp_no_silence_file_list[2], 5)\n",
    "print(num_frame)\n",
    "print(num_frame_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output feature (duration) normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.mean_variance_norm import MeanVarianceNorm\n",
    "dur_mvn_normaliser = MeanVarianceNorm(feature_dimension=dur_cmp_dim)\n",
    "dur_global_mean_vector = dur_mvn_normaliser.compute_mean(dur_cmp_no_silence_file_list[0: dur_train_file_number], 0, dur_cmp_dim)\n",
    "dur_global_std_vector = dur_mvn_normaliser.compute_std(dur_cmp_no_silence_file_list[0: dur_train_file_number], dur_global_mean_vector, 0, dur_cmp_dim)\n",
    "dur_mvn_normaliser.feature_normalisation(dur_cmp_no_silence_file_list, dur_cmp_no_silence_norm_file_list)\n",
    "dur_cmp_norm_info = np.concatenate((dur_global_mean_vector, dur_global_std_vector), axis=0)\n",
    "dur_cmp_norm_info = np.array(dur_cmp_norm_info, 'float32')\n",
    "fid = open(dur_cmp_norm_file, 'wb')\n",
    "dur_cmp_norm_info.tofile(fid)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[-0.7233047  -0.43827328 -0.4121524  -0.33808738 -0.66881937]\n",
      " [-0.7233047  -0.46908876  1.6973542  -0.10570705 -0.3786838 ]\n",
      " [-0.09544833 -0.19174956 -0.44511345 -0.33808738  1.3621298 ]\n",
      " [-0.7233047  -0.3458269  -0.4121524  -0.33808738 -0.66881937]\n",
      " [-0.30473378 -0.46908876  0.5766788  -0.22189721 -0.0885482 ]\n",
      " [ 0.11383712 -0.46908876  0.4118736   0.3977837  -0.66881937]\n",
      " [-0.9325901  -0.3150114  -0.4121524  -0.33808738 -0.5237516 ]\n",
      " [-0.9325901   1.164131   -0.44511345 -0.33808738 -0.5237516 ]\n",
      " [ 0.95097893 -0.22256503 -0.34623033 -0.29935732 -0.233616  ]\n",
      " [-0.9325901  -0.46908876 -0.4121524  -0.29935732 -0.0885482 ]\n",
      " [ 0.11383712 -0.37664235 -0.44511345 -0.33808738 -0.5237516 ]\n",
      " [-0.30473378  0.39374432 -0.44511345 -0.33808738 -0.233616  ]\n",
      " [ 0.95097893 -0.16093409 -0.34623033 -0.26062727 -0.3786838 ]\n",
      " [-0.7233047  -0.46908876  0.4118736  -0.33808738  0.3466552 ]\n",
      " [ 0.11383712 -0.37664235 -0.37919137 -0.29935732 -0.3786838 ]\n",
      " [-0.51401925 -0.46908876  1.4336659  -0.29935732  0.0565196 ]\n",
      " [ 0.11383712 -0.37664235 -0.4121524  -0.29935732 -0.233616  ]\n",
      " [-0.09544833 -0.46908876 -0.44511345 -0.33808738  0.3466552 ]\n",
      " [-0.51401925 -0.3458269  -0.2473472  -0.29935732 -0.233616  ]\n",
      " [-0.7233047   0.45537525 -0.4121524  -0.33808738 -0.0885482 ]\n",
      " [-0.09544833 -0.22256503 -0.4121524  -0.33808738 -0.5237516 ]\n",
      " [ 0.11383712  0.45537525 -0.44511345 -0.33808738 -0.0885482 ]\n",
      " [-0.30473378 -0.37664235 -0.44511345 -0.29935732 -0.66881937]\n",
      " [-0.9325901  -0.43827328  3.14764    -0.33808738  0.3466552 ]\n",
      " [-0.7233047   0.6094526   0.44483465 -0.29935732  0.3466552 ]\n",
      " [-0.51401925 -0.37664235 -0.37919137 -0.26062727 -0.3786838 ]\n",
      " [-0.51401925 -0.13011862 -0.34623033 -0.10570705 -0.66881937]\n",
      " [ 0.32312256 -0.46908876  0.80740607 -0.26062727 -0.233616  ]\n",
      " [-0.30473378 -0.3458269  -0.4121524  -0.22189721 -0.66881937]\n",
      " [-0.09544833 -0.46908876 -0.44511345  1.3660351  -0.5237516 ]\n",
      " [-0.09544833 -0.46908876  1.56551    -0.22189721  0.0565196 ]\n",
      " [-0.30473378 -0.40745783 -0.28030825 -0.26062727 -0.233616  ]\n",
      " [-0.09544833 -0.46908876 -0.28030825 -0.26062727 -0.5237516 ]\n",
      " [-0.30473378 -0.3150114  -0.4121524  -0.29935732 -0.3786838 ]\n",
      " [-0.7233047  -0.46908876  0.44483465 -0.18316716 -0.66881937]\n",
      " [ 0.95097893 -0.40745783 -0.34623033 -0.22189721 -0.0885482 ]\n",
      " [-0.9325901  -0.43827328  0.4118736  -0.26062727  0.0565196 ]\n",
      " [-0.09544833 -0.40745783 -0.44511345 -0.29935732 -0.5237516 ]\n",
      " [ 0.532408    0.85597634 -0.21438617 -0.33808738  0.6367908 ]\n",
      " [-0.51401925 -0.40745783 -0.37919137 -0.29935732 -0.3786838 ]\n",
      " [ 0.11383712 -0.40745783 -0.44511345 -0.33808738  0.3466552 ]\n",
      " [ 0.32312256 -0.43827328 -0.4121524  -0.33808738  1.217062  ]\n",
      " [-0.9325901  -0.46908876  0.44483465 -0.26062727  0.3466552 ]\n",
      " [ 1.7881207   0.3321134  -0.44511345 -0.06697699 -0.233616  ]\n",
      " [-0.7233047  -0.37664235 -0.4121524  -0.29935732 -0.5237516 ]\n",
      " [-0.7233047   0.20885152  1.4666269  -0.33808738  4.698689  ]\n",
      " [-0.09544833 -0.37664235 -0.18142512 -0.29935732 -0.0885482 ]\n",
      " [-0.51401925 -0.46908876  0.84036714 -0.33808738 -0.233616  ]\n",
      " [ 0.11383712 -0.43827328 -0.34623033 -0.26062727  0.0565196 ]\n",
      " [-0.9325901  -0.46908876 -0.44511345  0.78508425  1.0719942 ]\n",
      " [-0.7233047  -0.40745783 -0.4121524  -0.26062727 -0.233616  ]\n",
      " [-0.9325901  -0.46908876 -0.44511345  0.66889405  0.0565196 ]\n",
      " [ 0.32312256 -0.25338048 -0.4121524  -0.29935732 -0.233616  ]\n",
      " [-0.7233047  -0.46908876  0.84036714 -0.33808738 -0.66881937]\n",
      " [ 0.95097893 -0.3458269  -0.44511345 -0.1444371  -0.233616  ]\n",
      " [ 1.9974061  -0.03767221 -0.44511345 -0.22189721 -0.233616  ]\n",
      " [-0.51401925 -0.3458269  -0.4121524  -0.33808738 -0.66881937]\n",
      " [-0.51401925  0.6094526  -0.44511345 -0.33808738 -0.233616  ]\n",
      " [-0.09544833 -0.43827328 -0.44511345 -0.29935732  0.0565196 ]\n",
      " [ 0.95097893 -0.46908876  0.04930216 -0.18316716 -0.0885482 ]\n",
      " [-0.09544833 -0.22256503 -0.4121524  -0.29935732 -0.233616  ]\n",
      " [-0.30473378 -0.16093409  0.34595153 -0.29935732  0.6367908 ]\n",
      " [ 2.834548    0.05477419 -0.44511345 -0.33808738  0.2015874 ]\n",
      " [ 0.11383712 -0.3150114  -0.37919137 -0.22189721 -0.233616  ]\n",
      " [ 0.532408    0.30129793 -0.44511345 -0.33808738 -0.5237516 ]\n",
      " [-0.09544833 -0.25338048 -0.4121524  -0.26062727 -0.3786838 ]\n",
      " [-0.9325901  -0.46908876  1.3677437  -0.29935732 -0.0885482 ]\n",
      " [ 0.95097893 -0.40745783 -0.4121524  -0.29935732 -0.66881937]\n",
      " [-0.7233047  -0.46908876 -0.44511345 -0.33808738  0.6367908 ]\n",
      " [-0.09544833 -0.25338048 -0.2473472  -0.29935732 -0.3786838 ]\n",
      " [-0.30473378  1.9345177  -0.44511345 -0.33808738  2.3776042 ]\n",
      " [-0.7233047  -0.19174956 -0.44511345 -0.29935732 -0.5237516 ]\n",
      " [ 3.2531188  -0.46908876  1.0710944  -0.22189721 -0.3786838 ]\n",
      " [-0.51401925  0.36292887 -0.44511345 -0.29935732 -0.0885482 ]\n",
      " [-0.9325901  -0.43827328 -0.44511345 -0.29935732 -0.66881937]\n",
      " [-0.7233047  -0.46908876  0.6426009  -0.29935732  0.0565196 ]\n",
      " [ 2.6252625   0.5170062  -0.44511345 -0.1444371  -0.66881937]\n",
      " [-0.9325901  -0.09930315 -0.4121524  -0.33808738 -0.5237516 ]\n",
      " [-0.09544833  0.701899   -0.44511345 -0.33808738 -0.233616  ]\n",
      " [ 0.7416935  -0.06848768 -0.34623033 -0.26062727 -0.0885482 ]\n",
      " [-0.9325901  -0.46908876 -0.44511345 -0.29935732 -0.0885482 ]\n",
      " [-0.51401925 -0.3458269  -0.4121524  -0.33808738 -0.5237516 ]\n",
      " [-0.7233047   0.20885152 -0.44511345 -0.26062727 -0.233616  ]\n",
      " [ 0.532408   -0.22256503 -0.28030825 -0.29935732 -0.233616  ]\n",
      " [-0.9325901  -0.46908876  0.44483465 -0.33808738 -0.0885482 ]\n",
      " [ 0.11383712 -0.37664235 -0.34623033 -0.26062727 -0.233616  ]\n",
      " [ 0.7416935   0.02395872  0.6096398  -0.29935732  0.3466552 ]\n",
      " [-0.30473378 -0.40745783 -0.4121524  -0.26062727 -0.3786838 ]\n",
      " [-0.09544833 -0.46908876 -0.44511345 -0.33808738  0.3466552 ]\n",
      " [-0.09544833 -0.37664235 -0.21438617 -0.26062727 -0.233616  ]\n",
      " [-0.51401925  0.30129793 -0.44511345 -0.29935732 -0.3786838 ]\n",
      " [-0.09544833 -0.22256503 -0.44511345 -0.33808738 -0.3786838 ]\n",
      " [-0.7233047   0.701899   -0.44511345 -0.29935732 -0.5237516 ]\n",
      " [-0.09544833 -0.3150114  -0.4121524  -0.33808738 -0.66881937]\n",
      " [-0.9325901  -0.46908876  2.7850685  -0.33808738  2.6677399 ]\n",
      " [-0.7233047   1.0716846   0.04930216 -0.29935732 -0.3786838 ]\n",
      " [-0.51401925 -0.3458269  -0.37919137 -0.26062727 -0.3786838 ]\n",
      " [ 0.532408   -0.3458269  -0.3132693   0.04921318 -0.66881937]\n",
      " [-0.51401925 -0.46908876  0.80740607 -0.29935732 -0.233616  ]\n",
      " [-0.30473378 -0.3458269  -0.4121524  -0.18316716 -0.66881937]\n",
      " [ 0.11383712 -0.46908876 -0.44511345  0.90127444 -0.3786838 ]\n",
      " [-0.30473378 -0.25338048 -0.44511345 -0.29935732 -0.5237516 ]\n",
      " [-0.51401925 -0.46908876  1.4666269  -0.22189721 -0.233616  ]\n",
      " [ 0.11383712 -0.46908876 -0.4121524  -0.29935732  0.0565196 ]\n",
      " [-0.7233047  -0.43827328 -0.37919137 -0.22189721 -0.66881937]\n",
      " [-0.09544833 -0.28419596 -0.4121524  -0.29935732 -0.3786838 ]\n",
      " [-0.7233047  -0.46908876  0.708523   -0.22189721 -0.66881937]\n",
      " [ 0.32312256 -0.37664235 -0.34623033 -0.22189721  0.491723  ]\n",
      " [-0.9325901  -0.40745783  0.28002945 -0.22189721  0.0565196 ]\n",
      " [ 0.11383712 -0.40745783 -0.44511345 -0.33808738 -0.5237516 ]\n",
      " [ 0.532408    0.94842273 -0.44511345 -0.33808738  0.6367908 ]\n",
      " [-0.30473378 -0.40745783 -0.34623033 -0.26062727  0.0565196 ]\n",
      " [-0.51401925 -0.3150114  -0.44511345 -0.33808738  0.2015874 ]\n",
      " [ 0.32312256 -0.40745783 -0.37919137 -0.33808738  0.6367908 ]\n",
      " [-0.9325901  -0.46908876  0.4777957  -0.33808738  0.6367908 ]\n",
      " [ 1.7881207   0.23966698 -0.44511345 -0.02824693 -0.233616  ]\n",
      " [-0.09544833 -0.37664235 -0.44511345 -0.26062727 -0.3786838 ]\n",
      " [-0.7233047   0.36292887  1.3018217  -0.33808738  1.9424009 ]\n",
      " [ 0.11383712 -0.3458269  -0.2473472  -0.29935732 -0.0885482 ]\n",
      " [-0.9325901  -0.46908876  0.87332815 -0.33808738 -0.5237516 ]\n",
      " [-0.09544833 -0.28419596 -0.4121524  -0.18316716 -0.5237516 ]\n",
      " [-0.51401925 -0.46908876 -0.44511345  0.94000447  0.491723  ]\n",
      " [-0.30473378 -0.46908876 -0.4121524  -0.22189721 -0.233616  ]\n",
      " [-0.51401925 -0.46908876 -0.44511345  0.3977837   0.3466552 ]\n",
      " [ 0.32312256 -0.28419596 -0.34623033 -0.33808738 -0.233616  ]\n",
      " [-0.30473378 -0.46908876  0.84036714 -0.33808738 -0.66881937]\n",
      " [ 1.7881207  -0.46908876 -0.44511345 -0.1444371   0.0565196 ]\n",
      " [ 0.532408   -0.40745783  0.21410736 -0.22189721 -0.5237516 ]\n",
      " [-0.09544833 -0.37664235 -0.4121524  -0.33808738 -0.66881937]\n",
      " [-0.9325901   0.6402681  -0.44511345 -0.33808738 -0.0885482 ]\n",
      " [-0.30473378 -0.46908876 -0.4121524  -0.29935732  0.3466552 ]\n",
      " [-0.51401925 -0.46908876  0.14818528 -0.26062727 -0.0885482 ]\n",
      " [-0.09544833 -0.22256503 -0.37919137 -0.33808738 -0.0885482 ]\n",
      " [-0.09544833  0.4245598  -0.37919137 -0.33808738 -0.0885482 ]\n",
      " [-0.51401925 -0.19174956 -0.4121524  -0.26062727 -0.66881937]\n",
      " [-0.7233047   0.4245598  -0.44511345 -0.33808738  0.2015874 ]\n",
      " [-0.09544833 -0.37664235 -0.4121524  -0.29935732 -0.3786838 ]\n",
      " [ 1.3695499  -0.22256503  0.01634112 -0.33808738 -0.3786838 ]\n",
      " [-0.09544833 -0.28419596 -0.37919137 -0.26062727 -0.233616  ]\n",
      " [-0.7233047  -0.3458269   1.2358996  -0.29935732  0.0565196 ]\n",
      " [ 0.532408   -0.3458269  -0.44511345 -0.29935732 -0.66881937]\n",
      " [ 0.7416935  -0.46908876 -0.44511345 -0.33808738 -0.0885482 ]\n",
      " [ 0.11383712 -0.3150114  -0.21438617 -0.29935732 -0.5237516 ]\n",
      " [ 0.11383712  2.088595   -0.44511345 -0.33808738  6.294435  ]]\n"
     ]
    }
   ],
   "source": [
    "tmp1, num1 = io_funcs.load_binary_file_frame(dur_cmp_no_silence_file_list[0], 5)\n",
    "tmp2, num2 = io_funcs.load_binary_file_frame(dur_cmp_no_silence_norm_file_list[0], 5)\n",
    "print(num1 == num2)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_cmp_norm_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_variance_file_dict = {'dur': dur_dur_var_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_ind = 0\n",
    "for feat in list(dur_out_dimension_dict.keys()):\n",
    "    feat_std_vector = np.array(dur_global_std_vector[:, feat_ind: feat_ind + dur_out_dimension_dict[feat]], 'float32')\n",
    "    fid = open(dur_variance_file_dict[feat], 'w')\n",
    "    feat_var_vector = feat_std_vector**2\n",
    "    feat_var_vector.tofile(fid)\n",
    "    fid.close()\n",
    "    feat_ind += dur_out_dimension_dict[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.77816306 32.451236   30.33884862 25.81974051  6.89332861]]\n",
      "[[  22.830841 1053.0828    920.4457    666.659      47.51798 ]]\n"
     ]
    }
   ],
   "source": [
    "print(dur_global_std_vector)\n",
    "print(feat_var_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DurationDataset(data.Dataset):\n",
    "    def __init__(self, lab_file_list, cmp_file_list, lab_dim=368, cmp_dim=5):\n",
    "        assert(len(lab_file_list) == len(cmp_file_list))\n",
    "        for i in range(len(lab_file_list)):\n",
    "            lab_basename = os.path.splitext(os.path.basename(lab_file_list[i]))[0]\n",
    "            cmp_basename = os.path.splitext(os.path.basename(cmp_file_list[i]))[0]\n",
    "#             print(lab_basename)\n",
    "#             print(cmp_basename)\n",
    "#             print('*' * 20)\n",
    "            assert lab_basename == cmp_basename\n",
    "        self.lab_file_list = lab_file_list\n",
    "        self.cmp_file_list = cmp_file_list\n",
    "        self.lab_dim = lab_dim\n",
    "        self.cmp_dim = cmp_dim\n",
    "        self.io_funcs = BinaryIOCollection()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.lab_file_list)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        X = torch.from_numpy(self.io_funcs.load_binary_file_frame(self.lab_file_list[ind], self.lab_dim)[0])\n",
    "        Y = torch.from_numpy(self.io_funcs.load_binary_file_frame(self.cmp_file_list[ind], self.cmp_dim)[0])\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    def func(p):\n",
    "        return p[0].size(0)\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    max_seq_len = max(batch, key=func)[0].size(0)\n",
    "    min_seq_len = min(batch, key=func)[0].size(0)\n",
    "    \n",
    "    lab_dim = batch[0][0].size(1)\n",
    "    cmp_dim = batch[0][1].size(1)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if max_seq_len <= 2 * min_seq_len:\n",
    "        sample_len = int(min_seq_len/2)\n",
    "    else:\n",
    "        sample_len = min_seq_len\n",
    "    \n",
    "    \n",
    "    total_sample_num = 0\n",
    "    for i in range(batch_size):\n",
    "        lab = batch[i][0]\n",
    "        cmp = batch[i][1]\n",
    "        num_seq = math.ceil(lab.size(0)/sample_len)\n",
    "        total_sample_num += num_seq\n",
    "\n",
    "\n",
    "    \n",
    "    labs = torch.zeros(total_sample_num, sample_len, lab_dim)\n",
    "    cmps = torch.zeros(total_sample_num, sample_len, cmp_dim)\n",
    "    \n",
    "    curr_sample_ind = 0\n",
    "    for i in range(batch_size):\n",
    "        ind_in_file = 0\n",
    "        for j in range(math.floor(batch[i][0].size(0)/sample_len)):\n",
    "            labs[curr_sample_ind].copy_(batch[i][0][ind_in_file * sample_len: (ind_in_file+1) * sample_len][:])\n",
    "            cmps[curr_sample_ind].copy_(batch[i][1][ind_in_file * sample_len: (ind_in_file+1) * sample_len][:])\n",
    "            ind_in_file += 1\n",
    "            curr_sample_ind += 1\n",
    "        if batch[i][0].size(0) % sample_len != 0:\n",
    "            labs[curr_sample_ind].copy_(batch[i][0][-sample_len:][:])\n",
    "            cmps[curr_sample_ind].copy_(batch[i][1][-sample_len:][:])\n",
    "            curr_sample_ind += 1\n",
    "    \n",
    "    assert(curr_sample_ind == total_sample_num)\n",
    "    \n",
    "#     print(\"lab dimension: \" + str(lab_dim))\n",
    "#     print(\"cmp dimension: \" + str(cmp_dim))\n",
    "#     seq_len_list = [i[0].size(0) for i in batch]\n",
    "#     print(\"sequence length for each file: \" + str(seq_len_list))\n",
    "#     print('max sequence length of original file: ', str(max_seq_len))\n",
    "#     print('min sequence length of original file: ', str(min_seq_len))\n",
    "#     print(\"sample length: \", str(sample_len))\n",
    "#     print('total_sample_num: ' + str(total_sample_num))\n",
    "    \n",
    "#     torch.set_printoptions(profile=\"full\")\n",
    "#     print(batch[0][1])\n",
    "#     print(cmps)\n",
    "#     torch.set_printoptions(profile=\"default\")\n",
    "    \n",
    "    return labs, cmps, sample_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DurationModel(nn.Module):\n",
    "    def __init__(self, dur_lab_dim, dur_cmp_dim):\n",
    "        super(DurationModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(dur_lab_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "#         self.fc4 = nn.Linear(512, dur_cmp_dim)\n",
    "        self.fc5 = nn.Linear(512, dur_cmp_dim)\n",
    "        \n",
    "    def forward(self, dur_lab):\n",
    "        res = F.relu(self.fc1(dur_lab))\n",
    "        res = F.relu(self.fc2(res))\n",
    "        res = F.relu(self.fc3(res))\n",
    "#         res = self.fc4(res)\n",
    "        res = F.relu(self.fc4(res))\n",
    "        res = self.fc5(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, epoch):\n",
    "    model.train()\n",
    "    for batch_ind, batch in enumerate(train_loader):\n",
    "        lab, cmp = Variable(batch[0]), Variable(batch[1])\n",
    "        loss = criterion(model(lab), cmp)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_ind % log_interval == 0:\n",
    "            val_loss = evaluate(model, valid_loader)\n",
    "            train_loss = loss.item()\n",
    "            epoch_progress = 100. * batch_ind / len(train_loader)\n",
    "            print('Train Epoch: {}({:.0f}%)\\tTrain Loss: {:.6f}\\tVal Loss: {:.6f}'.format(\n",
    "                epoch, epoch_progress, train_loss, val_loss))\n",
    "            \n",
    "            \n",
    "def evaluate(model, valid_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    n_examples = 0\n",
    "    for batch_ind, batch in enumerate(valid_loader):\n",
    "        lab, cmp, sample_len = Variable(batch[0], volatile=True), Variable(batch[1]), batch[2]\n",
    "        output = model(lab)\n",
    "        loss = criterion(output, cmp, size_average=False).item()\n",
    "#         print('loss without average: ' + str(loss))\n",
    "        total_loss += loss\n",
    "        n = len(lab)\n",
    "#         print('num samples this batch: ' + str(n))\n",
    "#         print(cmp.size())\n",
    "        n_examples += n\n",
    "    \n",
    "    total_loss /= (n_examples * sample_len * cmp.size()[-1])\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dur_train_file_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-95d2fff5dbe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO to implement cross-validation, print something here to see whether could do normalisation in Pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_train_file_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# batch_size = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dur_train_set = DurationDataset([dur_lab_no_silence_norm_file_list[0]] * dur_train_file_number,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#                                 [dur_cmp_no_silence_norm_file_list[0]] * dur_train_file_number)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dur_train_file_number' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO to implement cross-validation, print something here to see whether could do normalisation in Pytorch\n",
    "batch_size = int(dur_train_file_number)\n",
    "# batch_size = 1\n",
    "# dur_train_set = DurationDataset([dur_lab_no_silence_norm_file_list[0]] * dur_train_file_number, \n",
    "#                                 [dur_cmp_no_silence_norm_file_list[0]] * dur_train_file_number)\n",
    "# dur_valid_set = DurationDataset(dur_lab_no_silence_norm_file_list[dur_train_file_number: dur_train_file_number + dur_valid_file_number],\n",
    "#                                 dur_cmp_no_silence_norm_file_list[dur_train_file_number: dur_train_file_number + dur_valid_file_number])\n",
    "dur_train_set = DurationDataset(dur_lab_no_silence_norm_file_list[:dur_train_file_number], dur_cmp_no_silence_norm_file_list[:dur_train_file_number])\n",
    "dur_valid_set = DurationDataset(dur_lab_no_silence_norm_file_list[:dur_valid_file_number], dur_cmp_no_silence_norm_file_list[:dur_valid_file_number])\n",
    "dur_train_loader = data.DataLoader(dur_train_set, shuffle=False, batch_size=batch_size, collate_fn=collate_fn)\n",
    "dur_valid_loader = data.DataLoader(dur_valid_set, shuffle=False, batch_size=dur_valid_file_number, collate_fn=collate_fn)\n",
    "\n",
    "tmp = next(iter(dur_train_loader))\n",
    "lab_, cmp_, _ = tmp\n",
    "print(lab_.size())\n",
    "print(cmp_.size())\n",
    "print(len(lab_))\n",
    "print(len(Variable(lab_)))\n",
    "print(len(dur_valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=368, out_features=512, bias=True)\n",
      "  (1): Dropout(p=0.5)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (4): Dropout(p=0.5)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (7): Dropout(p=0.5)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (10): Dropout(p=0.5)\n",
      "  (11): ReLU()\n",
      "  (12): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongliang/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1(0%)\tTrain Loss: 1.015382\tVal Loss: 0.419610\n",
      "Train Epoch: 2(0%)\tTrain Loss: 1.010938\tVal Loss: 0.411266\n",
      "Train Epoch: 3(0%)\tTrain Loss: 1.006758\tVal Loss: 0.399702\n",
      "Train Epoch: 4(0%)\tTrain Loss: 0.998417\tVal Loss: 0.385279\n",
      "Train Epoch: 5(0%)\tTrain Loss: 0.984328\tVal Loss: 0.376172\n",
      "Train Epoch: 6(0%)\tTrain Loss: 0.969366\tVal Loss: 0.382484\n",
      "Train Epoch: 7(0%)\tTrain Loss: 0.957654\tVal Loss: 0.402373\n",
      "Train Epoch: 8(0%)\tTrain Loss: 0.961003\tVal Loss: 0.406695\n",
      "Train Epoch: 9(0%)\tTrain Loss: 0.959084\tVal Loss: 0.397913\n",
      "Train Epoch: 10(0%)\tTrain Loss: 0.951252\tVal Loss: 0.386501\n",
      "Train Epoch: 11(0%)\tTrain Loss: 0.942314\tVal Loss: 0.380220\n",
      "Train Epoch: 12(0%)\tTrain Loss: 0.938326\tVal Loss: 0.372340\n",
      "Train Epoch: 13(0%)\tTrain Loss: 0.930071\tVal Loss: 0.362142\n",
      "Train Epoch: 14(0%)\tTrain Loss: 0.918603\tVal Loss: 0.350061\n",
      "Train Epoch: 15(0%)\tTrain Loss: 0.902814\tVal Loss: 0.339645\n",
      "Train Epoch: 16(0%)\tTrain Loss: 0.880264\tVal Loss: 0.329850\n",
      "Train Epoch: 17(0%)\tTrain Loss: 0.857533\tVal Loss: 0.306586\n",
      "Train Epoch: 18(0%)\tTrain Loss: 0.834276\tVal Loss: 0.292048\n",
      "Train Epoch: 19(0%)\tTrain Loss: 0.809564\tVal Loss: 0.298119\n",
      "Train Epoch: 20(0%)\tTrain Loss: 0.801429\tVal Loss: 0.290930\n",
      "Train Epoch: 21(0%)\tTrain Loss: 0.772095\tVal Loss: 0.284072\n",
      "Train Epoch: 22(0%)\tTrain Loss: 0.757804\tVal Loss: 0.286300\n",
      "Train Epoch: 23(0%)\tTrain Loss: 0.733682\tVal Loss: 0.287193\n",
      "Train Epoch: 24(0%)\tTrain Loss: 0.731092\tVal Loss: 0.274053\n",
      "Train Epoch: 25(0%)\tTrain Loss: 0.702096\tVal Loss: 0.267558\n",
      "Train Epoch: 26(0%)\tTrain Loss: 0.695804\tVal Loss: 0.268032\n",
      "Train Epoch: 27(0%)\tTrain Loss: 0.683559\tVal Loss: 0.264614\n",
      "Train Epoch: 28(0%)\tTrain Loss: 0.663856\tVal Loss: 0.260304\n",
      "Train Epoch: 29(0%)\tTrain Loss: 0.654608\tVal Loss: 0.261688\n",
      "Train Epoch: 30(0%)\tTrain Loss: 0.635611\tVal Loss: 0.258574\n",
      "Train Epoch: 31(0%)\tTrain Loss: 0.620457\tVal Loss: 0.255141\n",
      "Train Epoch: 32(0%)\tTrain Loss: 0.617246\tVal Loss: 0.253845\n",
      "Train Epoch: 33(0%)\tTrain Loss: 0.601041\tVal Loss: 0.257648\n",
      "Train Epoch: 34(0%)\tTrain Loss: 0.595140\tVal Loss: 0.247706\n",
      "Train Epoch: 35(0%)\tTrain Loss: 0.582408\tVal Loss: 0.235999\n",
      "Train Epoch: 36(0%)\tTrain Loss: 0.567004\tVal Loss: 0.233945\n",
      "Train Epoch: 37(0%)\tTrain Loss: 0.553148\tVal Loss: 0.234593\n",
      "Train Epoch: 38(0%)\tTrain Loss: 0.544183\tVal Loss: 0.233024\n",
      "Train Epoch: 39(0%)\tTrain Loss: 0.532991\tVal Loss: 0.226233\n",
      "Train Epoch: 40(0%)\tTrain Loss: 0.533386\tVal Loss: 0.226448\n",
      "Train Epoch: 41(0%)\tTrain Loss: 0.512426\tVal Loss: 0.220029\n",
      "Train Epoch: 42(0%)\tTrain Loss: 0.502460\tVal Loss: 0.208304\n",
      "Train Epoch: 43(0%)\tTrain Loss: 0.504806\tVal Loss: 0.203184\n",
      "Train Epoch: 44(0%)\tTrain Loss: 0.489336\tVal Loss: 0.199578\n",
      "Train Epoch: 45(0%)\tTrain Loss: 0.473719\tVal Loss: 0.191889\n",
      "Train Epoch: 46(0%)\tTrain Loss: 0.470371\tVal Loss: 0.190934\n",
      "Train Epoch: 47(0%)\tTrain Loss: 0.465747\tVal Loss: 0.188446\n",
      "Train Epoch: 48(0%)\tTrain Loss: 0.452780\tVal Loss: 0.180686\n",
      "Train Epoch: 49(0%)\tTrain Loss: 0.443094\tVal Loss: 0.179584\n",
      "Train Epoch: 50(0%)\tTrain Loss: 0.427727\tVal Loss: 0.177897\n",
      "Train Epoch: 51(0%)\tTrain Loss: 0.432939\tVal Loss: 0.172943\n",
      "Train Epoch: 52(0%)\tTrain Loss: 0.425390\tVal Loss: 0.167496\n",
      "Train Epoch: 53(0%)\tTrain Loss: 0.411096\tVal Loss: 0.166016\n",
      "Train Epoch: 54(0%)\tTrain Loss: 0.399021\tVal Loss: 0.159159\n",
      "Train Epoch: 55(0%)\tTrain Loss: 0.390576\tVal Loss: 0.156056\n",
      "Train Epoch: 56(0%)\tTrain Loss: 0.384091\tVal Loss: 0.154610\n",
      "Train Epoch: 57(0%)\tTrain Loss: 0.381563\tVal Loss: 0.150304\n",
      "Train Epoch: 58(0%)\tTrain Loss: 0.374151\tVal Loss: 0.148176\n",
      "Train Epoch: 59(0%)\tTrain Loss: 0.368923\tVal Loss: 0.146438\n",
      "Train Epoch: 60(0%)\tTrain Loss: 0.367046\tVal Loss: 0.140847\n",
      "Train Epoch: 61(0%)\tTrain Loss: 0.361177\tVal Loss: 0.138380\n",
      "Train Epoch: 62(0%)\tTrain Loss: 0.351109\tVal Loss: 0.138449\n",
      "Train Epoch: 63(0%)\tTrain Loss: 0.340673\tVal Loss: 0.136857\n",
      "Train Epoch: 64(0%)\tTrain Loss: 0.338743\tVal Loss: 0.133770\n",
      "Train Epoch: 65(0%)\tTrain Loss: 0.338870\tVal Loss: 0.135740\n",
      "Train Epoch: 66(0%)\tTrain Loss: 0.330443\tVal Loss: 0.133847\n",
      "Train Epoch: 67(0%)\tTrain Loss: 0.322282\tVal Loss: 0.128903\n",
      "Train Epoch: 68(0%)\tTrain Loss: 0.321676\tVal Loss: 0.128086\n",
      "Train Epoch: 69(0%)\tTrain Loss: 0.314574\tVal Loss: 0.128655\n",
      "Train Epoch: 70(0%)\tTrain Loss: 0.311180\tVal Loss: 0.125190\n",
      "Train Epoch: 71(0%)\tTrain Loss: 0.301846\tVal Loss: 0.121613\n",
      "Train Epoch: 72(0%)\tTrain Loss: 0.298460\tVal Loss: 0.122778\n",
      "Train Epoch: 73(0%)\tTrain Loss: 0.296640\tVal Loss: 0.123374\n",
      "Train Epoch: 74(0%)\tTrain Loss: 0.288318\tVal Loss: 0.121048\n",
      "Train Epoch: 75(0%)\tTrain Loss: 0.289624\tVal Loss: 0.118413\n",
      "Train Epoch: 76(0%)\tTrain Loss: 0.274111\tVal Loss: 0.118558\n",
      "Train Epoch: 77(0%)\tTrain Loss: 0.274973\tVal Loss: 0.118094\n",
      "Train Epoch: 78(0%)\tTrain Loss: 0.274724\tVal Loss: 0.118219\n",
      "Train Epoch: 79(0%)\tTrain Loss: 0.262605\tVal Loss: 0.114689\n",
      "Train Epoch: 80(0%)\tTrain Loss: 0.265803\tVal Loss: 0.112950\n",
      "Train Epoch: 81(0%)\tTrain Loss: 0.263228\tVal Loss: 0.113552\n",
      "Train Epoch: 82(0%)\tTrain Loss: 0.246965\tVal Loss: 0.113235\n",
      "Train Epoch: 83(0%)\tTrain Loss: 0.249927\tVal Loss: 0.109097\n",
      "Train Epoch: 84(0%)\tTrain Loss: 0.247865\tVal Loss: 0.107000\n",
      "Train Epoch: 85(0%)\tTrain Loss: 0.257673\tVal Loss: 0.110324\n",
      "Train Epoch: 86(0%)\tTrain Loss: 0.246650\tVal Loss: 0.107425\n",
      "Train Epoch: 87(0%)\tTrain Loss: 0.246608\tVal Loss: 0.105957\n",
      "Train Epoch: 88(0%)\tTrain Loss: 0.238351\tVal Loss: 0.103787\n",
      "Train Epoch: 89(0%)\tTrain Loss: 0.238072\tVal Loss: 0.103023\n",
      "Train Epoch: 90(0%)\tTrain Loss: 0.239900\tVal Loss: 0.102390\n",
      "Train Epoch: 91(0%)\tTrain Loss: 0.236562\tVal Loss: 0.102368\n",
      "Train Epoch: 92(0%)\tTrain Loss: 0.237937\tVal Loss: 0.102327\n",
      "Train Epoch: 93(0%)\tTrain Loss: 0.237492\tVal Loss: 0.102274\n",
      "Train Epoch: 94(0%)\tTrain Loss: 0.239076\tVal Loss: 0.102211\n",
      "Train Epoch: 95(0%)\tTrain Loss: 0.239834\tVal Loss: 0.102126\n",
      "Train Epoch: 96(0%)\tTrain Loss: 0.236227\tVal Loss: 0.102031\n",
      "Train Epoch: 97(0%)\tTrain Loss: 0.244259\tVal Loss: 0.101927\n",
      "Train Epoch: 98(0%)\tTrain Loss: 0.230564\tVal Loss: 0.101819\n",
      "Train Epoch: 99(0%)\tTrain Loss: 0.233984\tVal Loss: 0.101726\n",
      "Train Epoch: 100(0%)\tTrain Loss: 0.235918\tVal Loss: 0.101635\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "log_interval = 1\n",
    "epochs = 100\n",
    "duration_model = nn.Sequential(\n",
    "    nn.Linear(dur_lab_dim, 512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, dur_cmp_dim)\n",
    ")\n",
    "print(duration_model)\n",
    "optimizer = torch.optim.Adam(duration_model.parameters(), lr=lr)\n",
    "criterion = F.mse_loss\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[90], gamma=0.01)\n",
    "for epoch in range(1, epochs+1):\n",
    "    scheduler.step()\n",
    "    train(duration_model, dur_train_loader, dur_valid_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DurationModel(\n",
      "  (fc1): Linear(in_features=368, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongliang/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/yongliang/venv3/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1(0%)\tTrain Loss: 1.014548\tVal Loss: 0.423275\n",
      "Train Epoch: 2(0%)\tTrain Loss: 1.014099\tVal Loss: 0.422601\n",
      "Train Epoch: 3(0%)\tTrain Loss: 1.013744\tVal Loss: 0.422045\n",
      "Train Epoch: 4(0%)\tTrain Loss: 1.013454\tVal Loss: 0.421579\n",
      "Train Epoch: 5(0%)\tTrain Loss: 1.013213\tVal Loss: 0.421185\n",
      "Train Epoch: 6(0%)\tTrain Loss: 1.013007\tVal Loss: 0.420850\n",
      "Train Epoch: 7(0%)\tTrain Loss: 1.012827\tVal Loss: 0.420562\n",
      "Train Epoch: 8(0%)\tTrain Loss: 1.012666\tVal Loss: 0.420310\n",
      "Train Epoch: 9(0%)\tTrain Loss: 1.012519\tVal Loss: 0.420087\n",
      "Train Epoch: 10(0%)\tTrain Loss: 1.012381\tVal Loss: 0.419888\n",
      "Train Epoch: 11(0%)\tTrain Loss: 1.012249\tVal Loss: 0.419706\n",
      "Train Epoch: 12(0%)\tTrain Loss: 1.012122\tVal Loss: 0.419539\n",
      "Train Epoch: 13(0%)\tTrain Loss: 1.011996\tVal Loss: 0.419382\n",
      "Train Epoch: 14(0%)\tTrain Loss: 1.011870\tVal Loss: 0.419234\n",
      "Train Epoch: 15(0%)\tTrain Loss: 1.011744\tVal Loss: 0.419093\n",
      "Train Epoch: 16(0%)\tTrain Loss: 1.011618\tVal Loss: 0.418957\n",
      "Train Epoch: 17(0%)\tTrain Loss: 1.011491\tVal Loss: 0.418826\n",
      "Train Epoch: 18(0%)\tTrain Loss: 1.011362\tVal Loss: 0.418699\n",
      "Train Epoch: 19(0%)\tTrain Loss: 1.011232\tVal Loss: 0.418574\n",
      "Train Epoch: 20(0%)\tTrain Loss: 1.011099\tVal Loss: 0.418449\n",
      "Train Epoch: 21(0%)\tTrain Loss: 1.010963\tVal Loss: 0.418324\n",
      "Train Epoch: 22(0%)\tTrain Loss: 1.010824\tVal Loss: 0.418199\n",
      "Train Epoch: 23(0%)\tTrain Loss: 1.010681\tVal Loss: 0.418073\n",
      "Train Epoch: 24(0%)\tTrain Loss: 1.010535\tVal Loss: 0.417946\n",
      "Train Epoch: 25(0%)\tTrain Loss: 1.010385\tVal Loss: 0.417816\n",
      "Train Epoch: 26(0%)\tTrain Loss: 1.010229\tVal Loss: 0.417683\n",
      "Train Epoch: 27(0%)\tTrain Loss: 1.010068\tVal Loss: 0.417547\n",
      "Train Epoch: 28(0%)\tTrain Loss: 1.009902\tVal Loss: 0.417409\n",
      "Train Epoch: 29(0%)\tTrain Loss: 1.009729\tVal Loss: 0.417268\n",
      "Train Epoch: 30(0%)\tTrain Loss: 1.009550\tVal Loss: 0.417122\n",
      "Train Epoch: 31(0%)\tTrain Loss: 1.009363\tVal Loss: 0.416970\n",
      "Train Epoch: 32(0%)\tTrain Loss: 1.009169\tVal Loss: 0.416813\n",
      "Train Epoch: 33(0%)\tTrain Loss: 1.008966\tVal Loss: 0.416650\n",
      "Train Epoch: 34(0%)\tTrain Loss: 1.008754\tVal Loss: 0.416480\n",
      "Train Epoch: 35(0%)\tTrain Loss: 1.008532\tVal Loss: 0.416303\n",
      "Train Epoch: 36(0%)\tTrain Loss: 1.008300\tVal Loss: 0.416119\n",
      "Train Epoch: 37(0%)\tTrain Loss: 1.008056\tVal Loss: 0.415926\n",
      "Train Epoch: 38(0%)\tTrain Loss: 1.007800\tVal Loss: 0.415724\n",
      "Train Epoch: 39(0%)\tTrain Loss: 1.007530\tVal Loss: 0.415513\n",
      "Train Epoch: 40(0%)\tTrain Loss: 1.007246\tVal Loss: 0.415291\n",
      "Train Epoch: 41(0%)\tTrain Loss: 1.006948\tVal Loss: 0.415059\n",
      "Train Epoch: 42(0%)\tTrain Loss: 1.006634\tVal Loss: 0.414813\n",
      "Train Epoch: 43(0%)\tTrain Loss: 1.006302\tVal Loss: 0.414554\n",
      "Train Epoch: 44(0%)\tTrain Loss: 1.005951\tVal Loss: 0.414280\n",
      "Train Epoch: 45(0%)\tTrain Loss: 1.005580\tVal Loss: 0.413991\n",
      "Train Epoch: 46(0%)\tTrain Loss: 1.005186\tVal Loss: 0.413683\n",
      "Train Epoch: 47(0%)\tTrain Loss: 1.004768\tVal Loss: 0.413359\n",
      "Train Epoch: 48(0%)\tTrain Loss: 1.004324\tVal Loss: 0.413014\n",
      "Train Epoch: 49(0%)\tTrain Loss: 1.003852\tVal Loss: 0.412648\n",
      "Train Epoch: 50(0%)\tTrain Loss: 1.003351\tVal Loss: 0.412258\n",
      "Train Epoch: 51(0%)\tTrain Loss: 1.002818\tVal Loss: 0.411847\n",
      "Train Epoch: 52(0%)\tTrain Loss: 1.002250\tVal Loss: 0.411409\n",
      "Train Epoch: 53(0%)\tTrain Loss: 1.001644\tVal Loss: 0.410943\n",
      "Train Epoch: 54(0%)\tTrain Loss: 1.000998\tVal Loss: 0.410446\n",
      "Train Epoch: 55(0%)\tTrain Loss: 1.000308\tVal Loss: 0.409916\n",
      "Train Epoch: 56(0%)\tTrain Loss: 0.999572\tVal Loss: 0.409349\n",
      "Train Epoch: 57(0%)\tTrain Loss: 0.998787\tVal Loss: 0.408747\n",
      "Train Epoch: 58(0%)\tTrain Loss: 0.997950\tVal Loss: 0.408108\n",
      "Train Epoch: 59(0%)\tTrain Loss: 0.997058\tVal Loss: 0.407430\n",
      "Train Epoch: 60(0%)\tTrain Loss: 0.996108\tVal Loss: 0.406714\n",
      "Train Epoch: 61(0%)\tTrain Loss: 0.995097\tVal Loss: 0.405958\n",
      "Train Epoch: 62(0%)\tTrain Loss: 0.994023\tVal Loss: 0.405160\n",
      "Train Epoch: 63(0%)\tTrain Loss: 0.992884\tVal Loss: 0.404323\n",
      "Train Epoch: 64(0%)\tTrain Loss: 0.991675\tVal Loss: 0.403445\n",
      "Train Epoch: 65(0%)\tTrain Loss: 0.990396\tVal Loss: 0.402523\n",
      "Train Epoch: 66(0%)\tTrain Loss: 0.989045\tVal Loss: 0.401562\n",
      "Train Epoch: 67(0%)\tTrain Loss: 0.987621\tVal Loss: 0.400558\n",
      "Train Epoch: 68(0%)\tTrain Loss: 0.986124\tVal Loss: 0.399521\n",
      "Train Epoch: 69(0%)\tTrain Loss: 0.984554\tVal Loss: 0.398455\n",
      "Train Epoch: 70(0%)\tTrain Loss: 0.982914\tVal Loss: 0.397360\n",
      "Train Epoch: 71(0%)\tTrain Loss: 0.981208\tVal Loss: 0.396246\n",
      "Train Epoch: 72(0%)\tTrain Loss: 0.979442\tVal Loss: 0.395123\n",
      "Train Epoch: 73(0%)\tTrain Loss: 0.977625\tVal Loss: 0.394000\n",
      "Train Epoch: 74(0%)\tTrain Loss: 0.975763\tVal Loss: 0.392890\n",
      "Train Epoch: 75(0%)\tTrain Loss: 0.973867\tVal Loss: 0.391808\n",
      "Train Epoch: 76(0%)\tTrain Loss: 0.971948\tVal Loss: 0.390760\n",
      "Train Epoch: 77(0%)\tTrain Loss: 0.970019\tVal Loss: 0.389764\n",
      "Train Epoch: 78(0%)\tTrain Loss: 0.968091\tVal Loss: 0.388824\n",
      "Train Epoch: 79(0%)\tTrain Loss: 0.966178\tVal Loss: 0.387944\n",
      "Train Epoch: 80(0%)\tTrain Loss: 0.964295\tVal Loss: 0.387131\n",
      "Train Epoch: 81(0%)\tTrain Loss: 0.962453\tVal Loss: 0.386402\n",
      "Train Epoch: 82(0%)\tTrain Loss: 0.960666\tVal Loss: 0.385757\n",
      "Train Epoch: 83(0%)\tTrain Loss: 0.958943\tVal Loss: 0.385191\n",
      "Train Epoch: 84(0%)\tTrain Loss: 0.957292\tVal Loss: 0.384700\n",
      "Train Epoch: 85(0%)\tTrain Loss: 0.955717\tVal Loss: 0.384273\n",
      "Train Epoch: 86(0%)\tTrain Loss: 0.954220\tVal Loss: 0.383908\n",
      "Train Epoch: 87(0%)\tTrain Loss: 0.952800\tVal Loss: 0.383576\n",
      "Train Epoch: 88(0%)\tTrain Loss: 0.951450\tVal Loss: 0.383275\n",
      "Train Epoch: 89(0%)\tTrain Loss: 0.950165\tVal Loss: 0.382998\n",
      "Train Epoch: 90(0%)\tTrain Loss: 0.948937\tVal Loss: 0.382716\n",
      "Train Epoch: 91(0%)\tTrain Loss: 0.947754\tVal Loss: 0.382419\n",
      "Train Epoch: 92(0%)\tTrain Loss: 0.946606\tVal Loss: 0.382094\n",
      "Train Epoch: 93(0%)\tTrain Loss: 0.945481\tVal Loss: 0.381737\n",
      "Train Epoch: 94(0%)\tTrain Loss: 0.944368\tVal Loss: 0.381346\n",
      "Train Epoch: 95(0%)\tTrain Loss: 0.943255\tVal Loss: 0.380914\n",
      "Train Epoch: 96(0%)\tTrain Loss: 0.942136\tVal Loss: 0.380426\n",
      "Train Epoch: 97(0%)\tTrain Loss: 0.941002\tVal Loss: 0.379885\n",
      "Train Epoch: 98(0%)\tTrain Loss: 0.939846\tVal Loss: 0.379306\n",
      "Train Epoch: 99(0%)\tTrain Loss: 0.938666\tVal Loss: 0.378693\n",
      "Train Epoch: 100(0%)\tTrain Loss: 0.937459\tVal Loss: 0.378020\n",
      "Train Epoch: 101(0%)\tTrain Loss: 0.936220\tVal Loss: 0.377301\n",
      "Train Epoch: 102(0%)\tTrain Loss: 0.934946\tVal Loss: 0.376522\n",
      "Train Epoch: 103(0%)\tTrain Loss: 0.933630\tVal Loss: 0.375657\n",
      "Train Epoch: 104(0%)\tTrain Loss: 0.932272\tVal Loss: 0.374779\n",
      "Train Epoch: 105(0%)\tTrain Loss: 0.930871\tVal Loss: 0.373840\n",
      "Train Epoch: 106(0%)\tTrain Loss: 0.929428\tVal Loss: 0.372835\n",
      "Train Epoch: 107(0%)\tTrain Loss: 0.927936\tVal Loss: 0.371795\n",
      "Train Epoch: 108(0%)\tTrain Loss: 0.926396\tVal Loss: 0.370704\n",
      "Train Epoch: 109(0%)\tTrain Loss: 0.924808\tVal Loss: 0.369530\n",
      "Train Epoch: 110(0%)\tTrain Loss: 0.923165\tVal Loss: 0.368325\n",
      "Train Epoch: 111(0%)\tTrain Loss: 0.921469\tVal Loss: 0.367048\n",
      "Train Epoch: 112(0%)\tTrain Loss: 0.919719\tVal Loss: 0.365727\n",
      "Train Epoch: 113(0%)\tTrain Loss: 0.917916\tVal Loss: 0.364355\n",
      "Train Epoch: 114(0%)\tTrain Loss: 0.916058\tVal Loss: 0.362946\n",
      "Train Epoch: 115(0%)\tTrain Loss: 0.914144\tVal Loss: 0.361478\n",
      "Train Epoch: 116(0%)\tTrain Loss: 0.912176\tVal Loss: 0.359963\n",
      "Train Epoch: 117(0%)\tTrain Loss: 0.910153\tVal Loss: 0.358404\n",
      "Train Epoch: 118(0%)\tTrain Loss: 0.908077\tVal Loss: 0.356815\n",
      "Train Epoch: 119(0%)\tTrain Loss: 0.905954\tVal Loss: 0.355176\n",
      "Train Epoch: 120(0%)\tTrain Loss: 0.903787\tVal Loss: 0.353508\n",
      "Train Epoch: 121(0%)\tTrain Loss: 0.901577\tVal Loss: 0.351818\n",
      "Train Epoch: 122(0%)\tTrain Loss: 0.899327\tVal Loss: 0.350091\n",
      "Train Epoch: 123(0%)\tTrain Loss: 0.897044\tVal Loss: 0.348353\n",
      "Train Epoch: 124(0%)\tTrain Loss: 0.894730\tVal Loss: 0.346613\n",
      "Train Epoch: 125(0%)\tTrain Loss: 0.892390\tVal Loss: 0.344869\n",
      "Train Epoch: 126(0%)\tTrain Loss: 0.890035\tVal Loss: 0.343101\n",
      "Train Epoch: 127(0%)\tTrain Loss: 0.887668\tVal Loss: 0.341377\n",
      "Train Epoch: 128(0%)\tTrain Loss: 0.885295\tVal Loss: 0.339603\n",
      "Train Epoch: 129(0%)\tTrain Loss: 0.882923\tVal Loss: 0.337967\n",
      "Train Epoch: 130(0%)\tTrain Loss: 0.880560\tVal Loss: 0.336150\n",
      "Train Epoch: 131(0%)\tTrain Loss: 0.878213\tVal Loss: 0.334751\n",
      "Train Epoch: 132(0%)\tTrain Loss: 0.875885\tVal Loss: 0.332642\n",
      "Train Epoch: 133(0%)\tTrain Loss: 0.873587\tVal Loss: 0.332160\n",
      "Train Epoch: 134(0%)\tTrain Loss: 0.871348\tVal Loss: 0.328503\n",
      "Train Epoch: 135(0%)\tTrain Loss: 0.869314\tVal Loss: 0.333385\n",
      "Train Epoch: 136(0%)\tTrain Loss: 0.868335\tVal Loss: 0.325577\n",
      "Train Epoch: 137(0%)\tTrain Loss: 0.874073\tVal Loss: 0.395694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 138(0%)\tTrain Loss: 0.920938\tVal Loss: 0.444590\n",
      "Train Epoch: 139(0%)\tTrain Loss: 1.091513\tVal Loss: 0.367362\n",
      "Train Epoch: 140(0%)\tTrain Loss: 0.895048\tVal Loss: 0.333956\n",
      "Train Epoch: 141(0%)\tTrain Loss: 0.883293\tVal Loss: 0.342094\n",
      "Train Epoch: 142(0%)\tTrain Loss: 0.873264\tVal Loss: 0.323039\n",
      "Train Epoch: 143(0%)\tTrain Loss: 0.872296\tVal Loss: 0.347677\n",
      "Train Epoch: 144(0%)\tTrain Loss: 0.875028\tVal Loss: 0.332793\n",
      "Train Epoch: 145(0%)\tTrain Loss: 0.902637\tVal Loss: 0.369085\n",
      "Train Epoch: 146(0%)\tTrain Loss: 0.893660\tVal Loss: 0.347921\n",
      "Train Epoch: 147(0%)\tTrain Loss: 0.938882\tVal Loss: 0.334252\n",
      "Train Epoch: 148(0%)\tTrain Loss: 0.863919\tVal Loss: 0.318959\n",
      "Train Epoch: 149(0%)\tTrain Loss: 0.858907\tVal Loss: 0.328029\n",
      "Train Epoch: 150(0%)\tTrain Loss: 0.856649\tVal Loss: 0.316592\n",
      "Train Epoch: 151(0%)\tTrain Loss: 0.863284\tVal Loss: 0.346755\n",
      "Train Epoch: 152(0%)\tTrain Loss: 0.872251\tVal Loss: 0.338869\n",
      "Train Epoch: 153(0%)\tTrain Loss: 0.919249\tVal Loss: 0.336343\n",
      "Train Epoch: 154(0%)\tTrain Loss: 0.860158\tVal Loss: 0.317097\n",
      "Train Epoch: 155(0%)\tTrain Loss: 0.866077\tVal Loss: 0.333339\n",
      "Train Epoch: 156(0%)\tTrain Loss: 0.857175\tVal Loss: 0.318704\n",
      "Train Epoch: 157(0%)\tTrain Loss: 0.873443\tVal Loss: 0.335752\n",
      "Train Epoch: 158(0%)\tTrain Loss: 0.858306\tVal Loss: 0.320289\n",
      "Train Epoch: 159(0%)\tTrain Loss: 0.878832\tVal Loss: 0.331657\n",
      "Train Epoch: 160(0%)\tTrain Loss: 0.852501\tVal Loss: 0.314445\n",
      "Train Epoch: 161(0%)\tTrain Loss: 0.862913\tVal Loss: 0.329678\n",
      "Train Epoch: 162(0%)\tTrain Loss: 0.849748\tVal Loss: 0.314111\n",
      "Train Epoch: 163(0%)\tTrain Loss: 0.862966\tVal Loss: 0.330005\n",
      "Train Epoch: 164(0%)\tTrain Loss: 0.848632\tVal Loss: 0.313772\n",
      "Train Epoch: 165(0%)\tTrain Loss: 0.862798\tVal Loss: 0.329071\n",
      "Train Epoch: 166(0%)\tTrain Loss: 0.845976\tVal Loss: 0.311766\n",
      "Train Epoch: 167(0%)\tTrain Loss: 0.857467\tVal Loss: 0.327755\n",
      "Train Epoch: 168(0%)\tTrain Loss: 0.843270\tVal Loss: 0.310428\n",
      "Train Epoch: 169(0%)\tTrain Loss: 0.853905\tVal Loss: 0.327328\n",
      "Train Epoch: 170(0%)\tTrain Loss: 0.841446\tVal Loss: 0.309739\n",
      "Train Epoch: 171(0%)\tTrain Loss: 0.852343\tVal Loss: 0.327128\n",
      "Train Epoch: 172(0%)\tTrain Loss: 0.839677\tVal Loss: 0.308884\n",
      "Train Epoch: 173(0%)\tTrain Loss: 0.850171\tVal Loss: 0.326778\n",
      "Train Epoch: 174(0%)\tTrain Loss: 0.837803\tVal Loss: 0.307961\n",
      "Train Epoch: 175(0%)\tTrain Loss: 0.847678\tVal Loss: 0.326432\n",
      "Train Epoch: 176(0%)\tTrain Loss: 0.836038\tVal Loss: 0.307201\n",
      "Train Epoch: 177(0%)\tTrain Loss: 0.845635\tVal Loss: 0.326248\n",
      "Train Epoch: 178(0%)\tTrain Loss: 0.834441\tVal Loss: 0.306537\n",
      "Train Epoch: 179(0%)\tTrain Loss: 0.843838\tVal Loss: 0.326124\n",
      "Train Epoch: 180(0%)\tTrain Loss: 0.832923\tVal Loss: 0.305890\n",
      "Train Epoch: 181(0%)\tTrain Loss: 0.842018\tVal Loss: 0.325952\n",
      "Train Epoch: 182(0%)\tTrain Loss: 0.831408\tVal Loss: 0.305295\n",
      "Train Epoch: 183(0%)\tTrain Loss: 0.840285\tVal Loss: 0.325737\n",
      "Train Epoch: 184(0%)\tTrain Loss: 0.829889\tVal Loss: 0.304672\n",
      "Train Epoch: 185(0%)\tTrain Loss: 0.838388\tVal Loss: 0.325486\n",
      "Train Epoch: 186(0%)\tTrain Loss: 0.828404\tVal Loss: 0.304110\n",
      "Train Epoch: 187(0%)\tTrain Loss: 0.836644\tVal Loss: 0.325322\n",
      "Train Epoch: 188(0%)\tTrain Loss: 0.827049\tVal Loss: 0.303636\n",
      "Train Epoch: 189(0%)\tTrain Loss: 0.835141\tVal Loss: 0.325289\n",
      "Train Epoch: 190(0%)\tTrain Loss: 0.825848\tVal Loss: 0.303299\n",
      "Train Epoch: 191(0%)\tTrain Loss: 0.834043\tVal Loss: 0.325353\n",
      "Train Epoch: 192(0%)\tTrain Loss: 0.824740\tVal Loss: 0.302933\n",
      "Train Epoch: 193(0%)\tTrain Loss: 0.832830\tVal Loss: 0.325258\n",
      "Train Epoch: 194(0%)\tTrain Loss: 0.823515\tVal Loss: 0.302500\n",
      "Train Epoch: 195(0%)\tTrain Loss: 0.831384\tVal Loss: 0.325064\n",
      "Train Epoch: 196(0%)\tTrain Loss: 0.822255\tVal Loss: 0.302095\n",
      "Train Epoch: 197(0%)\tTrain Loss: 0.829984\tVal Loss: 0.324849\n",
      "Train Epoch: 198(0%)\tTrain Loss: 0.821005\tVal Loss: 0.301684\n",
      "Train Epoch: 199(0%)\tTrain Loss: 0.828530\tVal Loss: 0.324640\n",
      "Train Epoch: 200(0%)\tTrain Loss: 0.819802\tVal Loss: 0.301351\n"
     ]
    }
   ],
   "source": [
    "lr = 0.25\n",
    "log_interval = 1\n",
    "epochs = 200\n",
    "duration_model = DurationModel(dur_lab_dim, dur_cmp_dim)\n",
    "print(duration_model)\n",
    "optimizer = torch.optim.SGD(duration_model.parameters(), lr=lr)\n",
    "criterion = F.mse_loss\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(duration_model, dur_train_loader, dur_valid_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_nn_mdl_file = os.path.join(dur_nn_mdl_dir, 'dur_nn_mdl.pt')\n",
    "torch.save(duration_model.state_dict(), dur_nn_mdl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files for test: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dur_lab_no_silence_norm_file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f1ffb56fb069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'files for test: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_lab_no_silence_norm_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_cmp_no_silence_norm_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_cmp_no_silence_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dur_lab_no_silence_norm_file_list' is not defined"
     ]
    }
   ],
   "source": [
    "print('files for test: ')\n",
    "print(dur_lab_no_silence_norm_file_list[-1])\n",
    "print(dur_cmp_no_silence_norm_file_list[-1])\n",
    "print(dur_cmp_no_silence_file_list[-1])\n",
    "print('*' * 20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_lab, num_input_frame = io_funcs.load_binary_file_frame(dur_lab_no_silence_norm_file_list[-1], 368)\n",
    "target_cmp, num_target_frame = io_funcs.load_binary_file_frame(dur_cmp_no_silence_norm_file_list[-1], 5)\n",
    "assert(num_input_frame == num_target_frame)\n",
    "print('target output cmp: ')\n",
    "print(target_cmp[:10, :])\n",
    "\n",
    "input_lab = torch.from_numpy(input_lab)\n",
    "input_lab = input_lab[None, :, :]\n",
    "output_cmp = duration_model(input_lab)\n",
    "assert(output_cmp.size()[1] == num_target_frame)\n",
    "print('output cmp: ')\n",
    "print(output_cmp[0].detach().numpy()[:10, :])\n",
    "\n",
    "target_dur, num_dur_frame = io_funcs.load_binary_file_frame(dur_cmp_no_silence_file_list[-1], 5)\n",
    "assert(num_dur_frame == num_target_frame)\n",
    "print('target dur: ')\n",
    "print(target_dur[:10, :])\n",
    "\n",
    "fid = open(dur_cmp_norm_file, 'rb')\n",
    "dur_cmp_norm_info = np.fromfile(fid, dtype=np.float32)\n",
    "fid.close()\n",
    "dur_cmp_norm_info = dur_cmp_norm_info.reshape(2, -1)\n",
    "dur_cmp_mean = dur_cmp_norm_info[0, ]\n",
    "dur_cmp_std = dur_cmp_norm_info[1, ]\n",
    "\n",
    "test_tmp_file = os.path.join(dur_tmp_dir, 'dur_output.cmp')\n",
    "output_cmp = output_cmp.detach().numpy()[0]\n",
    "io_funcs.array_to_binary_file(output_cmp, test_tmp_file)\n",
    "\n",
    "print('mean: ', dur_cmp_mean)\n",
    "print('std: ', dur_cmp_std)\n",
    "\n",
    "test_dur_denormaliser = MeanVarianceNorm(feature_dimension=dur_cmp_dim)\n",
    "test_dur_denormaliser.feature_denormalisation([test_tmp_file], [test_tmp_file], dur_cmp_mean, dur_cmp_std)\n",
    "pred_dur = io_funcs.load_binary_file_frame(test_tmp_file, 5)\n",
    "print('predicted dur: ')\n",
    "print(type(pred_dur))\n",
    "print(pred_dur[0][:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acoustic model related\n",
    "\n",
    "# hardcoded\n",
    "acou_lab_dim = 377\n",
    "acou_cmp_dim = 187\n",
    "acou_train_file_number = 27\n",
    "acou_valid_file_number = 1\n",
    "acou_test_file_number = 1\n",
    "\n",
    "acou_mdl_dir = os.path.join(exp_dir, 'acoustic_model')\n",
    "if not os.path.exists(acou_mdl_dir):\n",
    "    os.makedirs(acou_mdl_dir)\n",
    "    \n",
    "acou_inter_dir = os.path.join(acou_mdl_dir, 'inter')\n",
    "if not os.path.exists(acou_inter_dir):\n",
    "    os.makedirs(acou_inter_dir)\n",
    "\n",
    "acou_lab_dir = os.path.join(acou_inter_dir, 'lab_' + str(acou_lab_dim))\n",
    "if not os.path.exists(acou_lab_dir):\n",
    "    os.makedirs(acou_lab_dir)\n",
    "    \n",
    "acou_lab_no_silence_dir = os.path.join(acou_inter_dir, 'lab_no_silence_' + str(acou_lab_dim))\n",
    "if not os.path.exists(acou_lab_no_silence_dir):\n",
    "    os.makedirs(acou_lab_no_silence_dir)\n",
    "    \n",
    "acou_lab_no_silence_norm_dir = os.path.join(acou_inter_dir, 'lab_no_silence_norm_' + str(acou_lab_dim))\n",
    "if not os.path.exists(acou_lab_no_silence_norm_dir):\n",
    "    os.makedirs(acou_lab_no_silence_norm_dir)\n",
    "\n",
    "'''\n",
    "acou_dur_dir = os.path.join(acou_inter_dir, 'dur')\n",
    "if not os.path.exists(acou_dur_dir):\n",
    "    os.makedirs(acou_dur_dir)\n",
    "'''\n",
    "\n",
    "    \n",
    "acou_cmp_dir = os.path.join(acou_inter_dir, 'cmp_' + str(acou_cmp_dim))\n",
    "if not os.path.exists(acou_cmp_dir):\n",
    "    os.makedirs(acou_cmp_dir)\n",
    "    \n",
    "acou_cmp_no_silence_dir = os.path.join(acou_inter_dir, 'cmp_no_silence_' + str(acou_cmp_dim))\n",
    "if not os.path.exists(acou_cmp_no_silence_dir):\n",
    "    os.makedirs(acou_cmp_no_silence_dir)\n",
    "    \n",
    "acou_cmp_no_silence_norm_dir = os.path.join(acou_inter_dir, 'cmp_no_silence_norm_' + str(acou_cmp_dim))\n",
    "if not os.path.exists(acou_cmp_no_silence_norm_dir):\n",
    "    os.makedirs(acou_cmp_no_silence_norm_dir)\n",
    "    \n",
    "acou_variance_dir = os.path.join(acou_inter_dir, 'variance')\n",
    "if not os.path.exists(acou_variance_dir):\n",
    "    os.makedirs(acou_variance_dir)\n",
    "    \n",
    "acou_nn_mdl_dir = os.path.join(acou_mdl_dir, 'mdl')\n",
    "if not os.path.exists(acou_nn_mdl_dir):\n",
    "    os.makedirs(acou_nn_mdl_dir)\n",
    "    \n",
    "    \n",
    "\n",
    "acou_lab_norm_file = os.path.join(acou_inter_dir, 'lab_norm_' + str(acou_lab_dim) + '.dat')\n",
    "acou_cmp_norm_file = os.path.join(acou_inter_dir, 'cmp_norm_' + str(acou_cmp_dim) + '.dat')\n",
    "\n",
    "acou_vuv_var_file = os.path.join(acou_variance_dir, 'vuv')\n",
    "acou_mgc_var_file = os.path.join(acou_variance_dir, 'mgc')\n",
    "acou_lf0_var_file = os.path.join(acou_variance_dir, 'lf0')\n",
    "acou_bap_var_file = os.path.join(acou_variance_dir, 'bap')\n",
    "    \n",
    "acou_lab_file_list = gen_file_list(acou_lab_dir, file_id_list, 'labbin')\n",
    "acou_lab_no_silence_file_list = gen_file_list(acou_lab_no_silence_dir, file_id_list, 'labbin')\n",
    "acou_lab_no_silence_norm_file_list = gen_file_list(acou_lab_no_silence_norm_dir, file_id_list, 'labbin')\n",
    "# dur_dur_file_list = gen_file_list(dur_dur_dir, file_id_list, 'dur')\n",
    "acou_cmp_file_list = gen_file_list(acou_cmp_dir, file_id_list, 'cmp')\n",
    "acou_cmp_no_silence_file_list = gen_file_list(acou_cmp_no_silence_dir, file_id_list, 'cmp')\n",
    "acou_cmp_no_silence_norm_file_list = gen_file_list(acou_cmp_no_silence_norm_dir, file_id_list, 'cmp')\n",
    "\n",
    "\n",
    "acou_lf0_file_list = gen_file_list(lf0_dir, file_id_list, 'lf0')\n",
    "acou_mgc_file_list = gen_file_list(mgc_dir, file_id_list, 'mgc')\n",
    "acou_bap_file_list = gen_file_list(bap_dir, file_id_list, 'bap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction from label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_lab_normaliser = HTSLabelNormalisation(question, add_frame_features=True, subphone_feats='full')\n",
    "acou_lab_normaliser.perform_normalisation(orig_lab_file_list, acou_lab_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove silence phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_silence_remover = SilenceRemover(n_cmp=acou_lab_dim, silence_pattern=silence_pattern, remove_frame_features=True, subphone_feats='full')\n",
    "acou_silence_remover.remove_silence(acou_lab_file_list, orig_lab_file_list, acou_lab_no_silence_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8635\n",
      "7201\n"
     ]
    }
   ],
   "source": [
    "_, num_frame = io_funcs.load_binary_file_frame(acou_lab_file_list[2], 377)\n",
    "_, num_frame_nn = io_funcs.load_binary_file_frame(acou_lab_no_silence_file_list[2], 377)\n",
    "print(num_frame)\n",
    "print(num_frame_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.04234528 1.         0.00325733]\n",
      " [0.         0.         0.         ... 0.04234528 0.99674267 0.00651466]\n",
      " [0.         0.         0.         ... 0.04234528 0.99348533 0.00977199]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.2925373  0.00895522 0.9940299 ]\n",
      " [0.         0.         0.         ... 0.2925373  0.00597015 0.99701494]\n",
      " [0.         0.         0.         ... 0.2925373  0.00298507 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "tmp, _ = io_funcs.load_binary_file_frame(acou_lab_file_list[2], 377)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_min_max_normaliser = MinMaxNormalisation(feature_dimension=acou_lab_dim, min_value=0.01, max_value=0.99)\n",
    "acou_min_max_normaliser.find_min_max_values(acou_lab_no_silence_file_list[0: acou_train_file_number])\n",
    "acou_min_max_normaliser.normalise_data(acou_lab_no_silence_file_list, acou_lab_no_silence_norm_file_list)\n",
    "acou_label_min_vector = acou_min_max_normaliser.min_vector\n",
    "acou_label_max_vector = acou_min_max_normaliser.max_vector\n",
    "acou_label_norm_info = np.concatenate((acou_label_min_vector, acou_label_max_vector), axis=0)\n",
    "acou_label_norm_info = np.array(acou_label_norm_info, 'float32')\n",
    "fid = open(acou_lab_norm_file, 'wb')\n",
    "acou_label_norm_info.tofile(fid)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 377)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acou_label_norm_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make output features for acoustic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"in\" & \"out\" just mean before & after feature composition \n",
    "like if we compute dynamic features, dimensions of out will be 3 times of in\n",
    "not really mean in & out of the network \n",
    "\"\"\" \n",
    "acou_in_dimension_dict = {'bap': 1, 'mgc': 60, 'lf0': 1} \n",
    "acou_out_dimension_dict = {'bap': 3, 'vuv': 1, 'mgc': 180, 'lf0': 3}\n",
    "# acou_in_dir_dict = {'bap': bap_dir, 'mgc': mgc_dir, 'lf0': lf0_dir}\n",
    "acou_in_file_list_dict = {'bap': acou_bap_file_list, 'mgc': acou_mgc_file_list, 'lf0': acou_lf0_file_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-3d490852f073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macou_acoustic_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAcousticComposition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_win\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_win\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_win\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macou_acoustic_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_nn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macou_in_file_list_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macou_cmp_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macou_in_dimension_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macou_out_dimension_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/third_party/merlin/src/frontend/acoustic_base.py\u001b[0m in \u001b[0;36mprepare_nn_data\u001b[0;34m(self, in_file_list_dict, out_file_list, in_dimension_dict, out_dimension_dict)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m### merge the data: like the cmp file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file_list_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_dimension_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dimension_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m### the real function to do the work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/third_party/merlin/src/frontend/acoustic_composition.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, in_file_list_dict, out_file_list, in_dimension_dict, out_dimension_dict)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dynamic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_stream_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                     \u001b[0mdelta_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dynamic_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feature_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0macc_features\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dynamic_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_feature_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/third_party/merlin/src/frontend/acoustic_base.py\u001b[0m in \u001b[0;36mcompute_dynamic_matrix\u001b[0;34m(self, data_matrix, dynamic_win, frame_number, dimension)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m###compute dynamic feature dimension by dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mdynamic_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dynamic_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mdynamic_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/third_party/merlin/src/frontend/acoustic_base.py\u001b[0m in \u001b[0;36mcompute_dynamic_vector\u001b[0;34m(self, vector, dynamic_win, frame_number)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mdelta_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdynamic_win\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mdelta_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acou_acoustic_worker = AcousticComposition(delta_win = delta_win, acc_win = acc_win)\n",
    "acou_acoustic_worker.prepare_nn_data(acou_in_file_list_dict, acou_cmp_file_list, acou_in_dimension_dict, acou_out_dimension_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 5)\n",
      "[[ 13.  72. 166.   2.  54.]\n",
      " [  9.  47.   1.  54.  32.]\n",
      " [  1.  18.   4.   4.   4.]\n",
      " [  3. 100.   1.   2.   6.]\n",
      " [  4.   5.   3.   3.   3.]\n",
      " [  1.  32.   1.   1.   3.]\n",
      " [  5.   3.   2.   2.   3.]\n",
      " [  2.  26.   1.   5.   8.]\n",
      " [  2.   3.   3.   7.   6.]\n",
      " [  6.  77.  17.   5.   5.]]\n",
      "(8640, 187)\n",
      "[[ 0.          0.          0.         ...  0.0016107   0.01590419\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ... -0.03265311  0.00975457\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.00190853  0.00436544\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ... -0.00899457 -0.00381122\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.02834933 -0.01433814\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.02132037 -0.0286779\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "feat, num_frame = io_funcs.load_binary_file_frame(dur_cmp_file_list[2], 5)\n",
    "print(feat.shape)\n",
    "print(feat[0:10, :])\n",
    "feat, num_frame = io_funcs.load_binary_file_frame(acou_cmp_file_list[2], 187)\n",
    "print(feat.shape)\n",
    "print(feat[0:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove silence phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_silence_remover = SilenceRemover(n_cmp = acou_cmp_dim, silence_pattern = silence_pattern, remove_frame_features = True, subphone_feats = 'full')\n",
    "acou_silence_remover.remove_silence(acou_cmp_file_list, orig_lab_file_list, acou_cmp_no_silence_file_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "7201\n"
     ]
    }
   ],
   "source": [
    "_, num_frame = io_funcs.load_binary_file_frame(acou_cmp_file_list[2], 187)\n",
    "_, num_frame_nn = io_funcs.load_binary_file_frame(acou_cmp_no_silence_file_list[2], 187)\n",
    "print(num_frame)\n",
    "print(num_frame_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output feature (dim 187) normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_mvn_normaliser = MeanVarianceNorm(feature_dimension=acou_cmp_dim)\n",
    "acou_global_mean_vector = acou_mvn_normaliser.compute_mean(acou_cmp_no_silence_file_list[0: acou_train_file_number], 0, acou_cmp_dim)\n",
    "acou_global_std_vector = acou_mvn_normaliser.compute_std(acou_cmp_no_silence_file_list[0: acou_train_file_number], acou_global_mean_vector, 0, acou_cmp_dim)\n",
    "acou_mvn_normaliser.feature_normalisation(acou_cmp_no_silence_file_list, acou_cmp_no_silence_norm_file_list)\n",
    "acou_cmp_norm_info = np.concatenate((acou_global_mean_vector, acou_global_std_vector), axis=0)\n",
    "acou_cmp_norm_info = np.array(acou_cmp_norm_info, 'float32')\n",
    "fid = open(acou_cmp_norm_file, 'wb')\n",
    "acou_cmp_norm_info.tofile(fid)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[ 1.4198911  -0.69523036 -0.5961235   0.45662737]\n",
      " [ 1.1533878  -0.47438782  0.7849358   0.45662737]\n",
      " [ 1.2379152  -0.63909817 -0.92615116  0.45662737]\n",
      " ...\n",
      " [ 1.288423   -0.9105048  -0.6175857  -1.4407294 ]\n",
      " [ 0.9759231  -0.0580794   1.3470236  -1.5170972 ]\n",
      " [ 1.265789   -0.49311343 -1.7196321  -1.5170972 ]]\n"
     ]
    }
   ],
   "source": [
    "tmp1, num1 = io_funcs.load_binary_file_frame(acou_cmp_no_silence_file_list[0], 187)\n",
    "tmp2, num2 = io_funcs.load_binary_file_frame(acou_cmp_no_silence_norm_file_list[0], 187)\n",
    "print(num1 == num2)\n",
    "print(tmp2[:, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 187)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.41241289, 1.80129955, 4.20871584, 0.22775437, 0.02732092,\n",
       "        0.06407295, 1.52488712, 0.86403745, 0.74400974, 0.59257406,\n",
       "        0.48412859, 0.3923912 , 0.30851035, 0.28519675, 0.36933757,\n",
       "        0.41165707, 0.32822327, 0.28492896, 0.29147884, 0.25433476,\n",
       "        0.20159926, 0.19080893, 0.15436258, 0.19601114, 0.19408261,\n",
       "        0.21055441, 0.14320896, 0.11563111, 0.09560336, 0.10722646,\n",
       "        0.11261904, 0.15451424, 0.13682862, 0.14987114, 0.14291312,\n",
       "        0.10829363, 0.10096106, 0.08894939, 0.07560818, 0.07302475,\n",
       "        0.08292949, 0.09943618, 0.1028903 , 0.09976558, 0.10206005,\n",
       "        0.10056028, 0.08708021, 0.07575486, 0.06951946, 0.06276173,\n",
       "        0.05988566, 0.06239593, 0.06657607, 0.06998015, 0.07346546,\n",
       "        0.07865112, 0.08020094, 0.07525864, 0.06977282, 0.06375563,\n",
       "        0.05756273, 0.05088478, 0.04439725, 0.04177266, 0.04052918,\n",
       "        0.04215691, 0.23098677, 0.14314069, 0.10022263, 0.07618567,\n",
       "        0.07058522, 0.06608377, 0.06079415, 0.05678634, 0.06002548,\n",
       "        0.07100924, 0.0704289 , 0.05589593, 0.05586179, 0.05853933,\n",
       "        0.04358428, 0.0472016 , 0.03954647, 0.04424097, 0.04026958,\n",
       "        0.04325016, 0.03644021, 0.03594404, 0.03191633, 0.03178075,\n",
       "        0.03469878, 0.03385955, 0.03373558, 0.03623361, 0.0301153 ,\n",
       "        0.02994606, 0.02777007, 0.0260447 , 0.02510259, 0.02616375,\n",
       "        0.02751757, 0.02628847, 0.02835548, 0.02947895, 0.0264891 ,\n",
       "        0.0262272 , 0.02554259, 0.02352404, 0.02176763, 0.0209435 ,\n",
       "        0.02154545, 0.02271469, 0.02250564, 0.02155565, 0.02238389,\n",
       "        0.02391988, 0.02306413, 0.02131459, 0.02075475, 0.02011121,\n",
       "        0.01887289, 0.01774064, 0.01678979, 0.01628225, 0.01628126,\n",
       "        0.01684994, 0.28003798, 0.23980382, 0.17091941, 0.14593449,\n",
       "        0.12961878, 0.126744  , 0.11563728, 0.11031958, 0.11288798,\n",
       "        0.13689955, 0.14123376, 0.11372157, 0.11102028, 0.12029052,\n",
       "        0.08935279, 0.09838665, 0.08014144, 0.09045165, 0.07751207,\n",
       "        0.08665168, 0.07314873, 0.07684392, 0.06867311, 0.06653555,\n",
       "        0.07056334, 0.066424  , 0.06465922, 0.07008776, 0.05870239,\n",
       "        0.06021639, 0.05804169, 0.05520671, 0.05401498, 0.05576374,\n",
       "        0.05579863, 0.05131929, 0.05433712, 0.05449566, 0.04867448,\n",
       "        0.05036331, 0.05040244, 0.04769661, 0.04553442, 0.04481849,\n",
       "        0.04598135, 0.0468513 , 0.04461324, 0.04208625, 0.04389333,\n",
       "        0.04569512, 0.04256402, 0.03959533, 0.03996718, 0.03983006,\n",
       "        0.03839369, 0.03716945, 0.03606939, 0.03533025, 0.03562297,\n",
       "        0.0364862 , 0.33659084]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acou_cmp_norm_info.shape)\n",
    "acou_global_std_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_variance_file_dict = {'vuv': acou_vuv_var_file,\n",
    "                           'mgc': acou_mgc_var_file,\n",
    "                           'lf0': acou_lf0_var_file,\n",
    "                           'bap': acou_bap_var_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_ind = 0\n",
    "for feat in list(acou_out_dimension_dict.keys()):\n",
    "    feat_std_vector = np.array(acou_global_std_vector[:, feat_ind: feat_ind + acou_out_dimension_dict[feat]], 'float32')\n",
    "    fid = open(acou_variance_file_dict[feat], 'w')\n",
    "    feat_var_vector = feat_std_vector**2\n",
    "    feat_var_vector.tofile(fid)\n",
    "    fid.close()\n",
    "    feat_ind += acou_out_dimension_dict[feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 27\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dur_train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9cc04446e74d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0macou_valid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macou_valid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macou_valid_file_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlab_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dur_train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO to implement cross-validation, print something here to see whether could do normalisation in Pytorch\n",
    "batch_size = int(acou_train_file_number)\n",
    "# batch_size = 1\n",
    "print('batch_size: ' + str(batch_size))\n",
    "acou_train_set = DurationDataset(acou_lab_no_silence_norm_file_list[:10], \n",
    "                                acou_cmp_no_silence_norm_file_list[:10], lab_dim=377, cmp_dim=187)\n",
    "acou_valid_set = DurationDataset(acou_lab_no_silence_norm_file_list[acou_train_file_number: acou_train_file_number + acou_valid_file_number],\n",
    "                                acou_cmp_no_silence_norm_file_list[acou_train_file_number: acou_train_file_number + acou_valid_file_number], lab_dim=377, cmp_dim=187)\n",
    "acou_train_loader = data.DataLoader(acou_train_set, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "acou_valid_loader = data.DataLoader(acou_valid_set, shuffle=True, batch_size=acou_valid_file_number, collate_fn=collate_fn)\n",
    "\n",
    "tmp = next(iter(dur_train_loader))\n",
    "lab_, cmp_, _ = tmp\n",
    "print(lab_.size())\n",
    "print(cmp_.size())\n",
    "print(len(Variable(lab_)))\n",
    "print(len(dur_valid_set))\n",
    "\n",
    "tmp = next(iter(acou_train_loader))\n",
    "lab_, cmp_, sp_len = tmp\n",
    "print(lab_.size())\n",
    "print(cmp_.size())\n",
    "print(len(Variable(lab_)))\n",
    "print(len(acou_valid_set))\n",
    "print(sp_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongliang/venv3/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1(0%)\tTrain Loss: 0.984347\tVal Loss: 0.863277\n",
      "Train Epoch: 2(0%)\tTrain Loss: 1.062275\tVal Loss: 0.783125\n",
      "Train Epoch: 3(0%)\tTrain Loss: 0.974228\tVal Loss: 0.786081\n",
      "Train Epoch: 4(0%)\tTrain Loss: 0.978735\tVal Loss: 0.784810\n",
      "Train Epoch: 5(0%)\tTrain Loss: 0.977458\tVal Loss: 0.782597\n",
      "Train Epoch: 6(0%)\tTrain Loss: 0.974964\tVal Loss: 0.779685\n",
      "Train Epoch: 7(0%)\tTrain Loss: 0.972507\tVal Loss: 0.776630\n",
      "Train Epoch: 8(0%)\tTrain Loss: 0.969165\tVal Loss: 0.774019\n",
      "Train Epoch: 9(0%)\tTrain Loss: 0.965468\tVal Loss: 0.772322\n",
      "Train Epoch: 10(0%)\tTrain Loss: 0.962575\tVal Loss: 0.770879\n",
      "Train Epoch: 11(0%)\tTrain Loss: 0.960082\tVal Loss: 0.769364\n",
      "Train Epoch: 12(0%)\tTrain Loss: 0.957539\tVal Loss: 0.767490\n",
      "Train Epoch: 13(0%)\tTrain Loss: 0.954855\tVal Loss: 0.765427\n",
      "Train Epoch: 14(0%)\tTrain Loss: 0.952160\tVal Loss: 0.763440\n",
      "Train Epoch: 15(0%)\tTrain Loss: 0.949404\tVal Loss: 0.761820\n",
      "Train Epoch: 16(0%)\tTrain Loss: 0.946651\tVal Loss: 0.760525\n",
      "Train Epoch: 17(0%)\tTrain Loss: 0.943908\tVal Loss: 0.759672\n",
      "Train Epoch: 18(0%)\tTrain Loss: 0.941206\tVal Loss: 0.759145\n",
      "Train Epoch: 19(0%)\tTrain Loss: 0.938543\tVal Loss: 0.758411\n",
      "Train Epoch: 20(0%)\tTrain Loss: 0.935908\tVal Loss: 0.757494\n",
      "Train Epoch: 21(0%)\tTrain Loss: 0.933237\tVal Loss: 0.757113\n",
      "Train Epoch: 22(0%)\tTrain Loss: 0.930663\tVal Loss: 0.756887\n",
      "Train Epoch: 23(0%)\tTrain Loss: 0.928174\tVal Loss: 0.756183\n",
      "Train Epoch: 24(0%)\tTrain Loss: 0.925720\tVal Loss: 0.755351\n",
      "Train Epoch: 25(0%)\tTrain Loss: 0.923367\tVal Loss: 0.755047\n",
      "Train Epoch: 26(0%)\tTrain Loss: 0.921034\tVal Loss: 0.755256\n",
      "Train Epoch: 27(0%)\tTrain Loss: 0.918777\tVal Loss: 0.755041\n",
      "Train Epoch: 28(0%)\tTrain Loss: 0.916584\tVal Loss: 0.754306\n",
      "Train Epoch: 29(0%)\tTrain Loss: 0.914378\tVal Loss: 0.754062\n",
      "Train Epoch: 30(0%)\tTrain Loss: 0.912243\tVal Loss: 0.754348\n",
      "Train Epoch: 31(0%)\tTrain Loss: 0.910097\tVal Loss: 0.754822\n",
      "Train Epoch: 32(0%)\tTrain Loss: 0.908008\tVal Loss: 0.754840\n",
      "Train Epoch: 33(0%)\tTrain Loss: 0.905942\tVal Loss: 0.754805\n",
      "Train Epoch: 34(0%)\tTrain Loss: 0.903909\tVal Loss: 0.755281\n",
      "Train Epoch: 35(0%)\tTrain Loss: 0.901907\tVal Loss: 0.755810\n",
      "Train Epoch: 36(0%)\tTrain Loss: 0.899948\tVal Loss: 0.755684\n",
      "Train Epoch: 37(0%)\tTrain Loss: 0.898026\tVal Loss: 0.755449\n",
      "Train Epoch: 38(0%)\tTrain Loss: 0.896140\tVal Loss: 0.755678\n",
      "Train Epoch: 39(0%)\tTrain Loss: 0.894252\tVal Loss: 0.756810\n",
      "Train Epoch: 40(0%)\tTrain Loss: 0.892420\tVal Loss: 0.756608\n",
      "Train Epoch: 41(0%)\tTrain Loss: 0.890540\tVal Loss: 0.757076\n",
      "Train Epoch: 42(0%)\tTrain Loss: 0.888752\tVal Loss: 0.756724\n",
      "Train Epoch: 43(0%)\tTrain Loss: 0.887059\tVal Loss: 0.756606\n",
      "Train Epoch: 44(0%)\tTrain Loss: 0.885487\tVal Loss: 0.756791\n",
      "Train Epoch: 45(0%)\tTrain Loss: 0.884016\tVal Loss: 0.754968\n",
      "Train Epoch: 46(0%)\tTrain Loss: 0.882640\tVal Loss: 0.755277\n",
      "Train Epoch: 47(0%)\tTrain Loss: 0.881380\tVal Loss: 0.752342\n",
      "Train Epoch: 48(0%)\tTrain Loss: 0.880114\tVal Loss: 0.753455\n",
      "Train Epoch: 49(0%)\tTrain Loss: 0.878896\tVal Loss: 0.751094\n",
      "Train Epoch: 50(0%)\tTrain Loss: 0.877769\tVal Loss: 0.749645\n"
     ]
    }
   ],
   "source": [
    "lr = 0.015\n",
    "log_interval = 1\n",
    "epochs = 50\n",
    "acoustic_model = nn.Sequential(\n",
    "    nn.Linear(acou_lab_dim, 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, acou_cmp_dim)\n",
    ")\n",
    "# acoustic_model = nn.Sequential(\n",
    "#     nn.Linear(acou_lab_dim, 512),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, acou_cmp_dim)\n",
    "# )\n",
    "optimizer = torch.optim.Adam(acoustic_model.parameters(), lr=lr)\n",
    "criterion = F.mse_loss\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(acoustic_model, acou_train_loader, acou_valid_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DurationModel(\n",
      "  (fc1): Linear(in_features=377, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=187, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-6c238c8645cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macoustic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macou_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macou_valid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-1b0cb7a56f82>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_ind\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "log_interval = 1\n",
    "epochs = 30\n",
    "acoustic_model = DurationModel(acou_lab_dim, acou_cmp_dim)\n",
    "print(acoustic_model)\n",
    "optimizer = torch.optim.SGD(acoustic_model.parameters(), lr=lr)\n",
    "criterion = F.mse_loss\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(acoustic_model, acou_train_loader, acou_valid_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "acou_nn_mdl_file = os.path.join(acou_nn_mdl_dir, 'acou_nn_mdl.pt')\n",
    "torch.save(acoustic_model.state_dict(), acou_nn_mdl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_id_list = file_id_list[-dur_test_file_number:]\n",
    "input_lab_file_list = orig_lab_file_list[-dur_test_file_number:]\n",
    "\n",
    "synth_dir = os.path.join(exp_dir, 'synth')\n",
    "if not os.path.exists(synth_dir):\n",
    "    os.makedirs(synth_dir)\n",
    "    \n",
    "wav_dir = os.path.join(synth_dir, 'wav')\n",
    "if not os.path.exists(wav_dir):\n",
    "    os.makedirs(wav_dir)\n",
    "    \n",
    "synth_inter_dir = os.path.join(synth_dir, 'inter')\n",
    "if not os.path.exists(synth_inter_dir):\n",
    "    os.makedirs(synth_inter_dir)\n",
    "    \n",
    "synth_dur_lab_norm_dir = os.path.join(synth_inter_dir, 'dur_lab_norm')\n",
    "if not os.path.exists(synth_dur_lab_norm_dir):\n",
    "    os.makedirs(synth_dur_lab_norm_dir)\n",
    "    \n",
    "synth_dur_cmp_pred_dir = os.path.join(synth_inter_dir, 'dur_cmp_pred')\n",
    "if not os.path.exists(synth_dur_cmp_pred_dir):\n",
    "    os.makedirs(synth_dur_cmp_pred_dir)\n",
    "    \n",
    "synth_dur_lab_file_list = gen_file_list(dur_lab_dir, synth_id_list, 'labbin')\n",
    "synth_dur_lab_norm_file_list = gen_file_list(synth_dur_lab_norm_dir, synth_id_list, 'labbin')\n",
    "synth_dur_cmp_pred_file_list = gen_file_list(synth_dur_cmp_pred_dir, synth_id_list, 'cmp')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "orig_lab_file_list = get_file_list_of_dir(lab_dir)\n",
    "file_id_list = get_file_id_list(orig_lab_file_list)\n",
    "dur_lab_file_list = gen_file_list(dur_lab_dir, file_id_list, 'labbin')\n",
    "dur_lab_no_silence_file_list = gen_file_list(dur_lab_no_silence_dir, file_id_list, 'labbin')\n",
    "dur_lab_no_silence_norm_file_list = gen_file_list(dur_lab_no_silence_norm_dir, file_id_list, 'labbin')\n",
    "dur_dur_file_list = gen_file_list(dur_dur_dir, file_id_list, 'dur')\n",
    "dur_cmp_file_list = gen_file_list(dur_cmp_dir, file_id_list, 'cmp')\n",
    "dur_cmp_no_silence_file_list = gen_file_list(dur_cmp_no_silence_dir, file_id_list, 'cmp')\n",
    "dur_cmp_no_silence_norm_file_list = gen_file_list(dur_cmp_no_silence_norm_dir, file_id_list, 'cmp')\n",
    "\n",
    "synth_acou_lab_norm_dir = os.path.join(synth_inter_dir, 'acou_lab_norm')\n",
    "if not os.path.exists(synth_acou_lab_norm_dir):\n",
    "    os.makedirs(synth_acou_lab_norm_dir)\n",
    "    \n",
    "synth_acou_cmp_pred_dir = os.path.join(synth_inter_dir, 'acou_cmp_pred')\n",
    "if not os.path.exists(synth_acou_cmp_pred_dir):\n",
    "    os.makedirs(synth_acou_cmp_pred_dir)\n",
    "    \n",
    "synth_acou_lab_file_list = gen_file_list(synth_acou_lab_norm_dir, synth_id_list, 'labbin')\n",
    "synth_acou_lab_norm_file_list = gen_file_list(synth_acou_lab_norm_dir, synth_id_list, 'labbin')\n",
    "synth_acou_cmp_pred_file_list = gen_file_list(synth_acou_cmp_pred_dir, synth_id_list, 'cmp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize label files for duration model (silence not removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dur_lab_normaliser = MinMaxNormalisation(feature_dimension = dur_lab_dim, min_value = 0.01, max_value = 0.99)\n",
    "synth_dur_lab_normaliser.load_min_max_values(dur_lab_norm_file)\n",
    "synth_dur_lab_normaliser.normalise_data(synth_dur_lab_file_list, synth_dur_lab_norm_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/inter/dur_lab_norm/nitech_jp_song070_f001_070.labbin\n",
      "num1:  55\n",
      "num2:  55\n"
     ]
    }
   ],
   "source": [
    "tmp1, num1 = io_funcs.load_binary_file_frame(synth_dur_lab_norm_file_list[0], 368)\n",
    "tmp2, num2 = io_funcs.load_binary_file_frame(synth_dur_lab_file_list[0], 368)\n",
    "print(synth_dur_lab_norm_file_list[0])\n",
    "print('num1: ', str(num1))\n",
    "print('num2: ', str(num2))\n",
    "# print(tmp1[0: 10, :])\n",
    "# print(synth_dur_lab_norm_file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dur_nn_mdl_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1230c30d7fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msynth_duration_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDurationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_lab_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdur_cmp_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msynth_duration_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdur_nn_mdl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msynth_duration_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dur_nn_mdl_file' is not defined"
     ]
    }
   ],
   "source": [
    "synth_duration_model = DurationModel(dur_lab_dim, dur_cmp_dim)\n",
    "synth_duration_model.load_state_dict(torch.load(dur_nn_mdl_file))\n",
    "synth_duration_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01988075, -0.0144904 , -0.00999507,  0.01847764, -0.04645242],\n",
       "       [ 0.02036698, -0.01061654, -0.01343583,  0.0174404 , -0.04564231],\n",
       "       [ 0.01980831, -0.01042566, -0.00955306,  0.01998632, -0.0467877 ],\n",
       "       [ 0.02019942, -0.01023069, -0.01224981,  0.01947055, -0.05132477],\n",
       "       [ 0.01836238, -0.0113967 , -0.01231135,  0.02014951, -0.04862119],\n",
       "       [ 0.01882902, -0.00813174, -0.01518269,  0.02333031, -0.04627261],\n",
       "       [ 0.021107  , -0.00600657, -0.01176079,  0.0198276 , -0.04381986],\n",
       "       [ 0.0204055 , -0.01126596, -0.00851345,  0.02269961, -0.04616012],\n",
       "       [ 0.02336671, -0.01064226, -0.00915501,  0.01942649, -0.05331106],\n",
       "       [ 0.0211011 , -0.01066624, -0.00971396,  0.01897801, -0.05050771],\n",
       "       [ 0.02177164, -0.0063715 , -0.01332739,  0.02292496, -0.0482948 ],\n",
       "       [ 0.01991749, -0.01176413, -0.00958858,  0.022183  , -0.04780466],\n",
       "       [ 0.02152749, -0.00871838, -0.0094396 ,  0.01820032, -0.04883516],\n",
       "       [ 0.02160495, -0.00902334, -0.00842657,  0.01813893, -0.04813948],\n",
       "       [ 0.02233695, -0.00627167, -0.01212846,  0.02281871, -0.04975304],\n",
       "       [ 0.02000985, -0.0104857 , -0.00913305,  0.0185012 , -0.04544366],\n",
       "       [ 0.02034886, -0.00883874, -0.01292951,  0.02004   , -0.04441091],\n",
       "       [ 0.02466314, -0.00551827, -0.00829346,  0.02096679, -0.04475518],\n",
       "       [ 0.02561073, -0.00908757, -0.00956327,  0.02331389, -0.05074487],\n",
       "       [ 0.015657  , -0.01219732, -0.00867762,  0.0229059 , -0.04609764],\n",
       "       [ 0.02242431, -0.00615517, -0.00844968,  0.01778708, -0.04793162],\n",
       "       [ 0.02261764, -0.01012719, -0.0063499 ,  0.02179973, -0.04866393],\n",
       "       [ 0.0212522 , -0.00870106, -0.00897789,  0.02179822, -0.04917058],\n",
       "       [ 0.01953165, -0.01275493, -0.00790976,  0.02340727, -0.04472835],\n",
       "       [ 0.01778242, -0.00453795, -0.00989285,  0.02066831, -0.04813165],\n",
       "       [ 0.02073765, -0.00727398, -0.0153682 ,  0.01954153, -0.04877986],\n",
       "       [ 0.02108555, -0.01399476, -0.00697911,  0.02233363, -0.04953229],\n",
       "       [ 0.02334613, -0.00921136, -0.01012079,  0.02100671, -0.05241745],\n",
       "       [ 0.02066823, -0.00631088, -0.01299729,  0.0181784 , -0.05004309],\n",
       "       [ 0.01553711, -0.00992007, -0.01279583,  0.01968436, -0.04825629],\n",
       "       [ 0.01792343, -0.0071792 , -0.01564012,  0.02551606, -0.04913801],\n",
       "       [ 0.0190844 , -0.01270271, -0.00887067,  0.01976652, -0.04723739],\n",
       "       [ 0.01790153, -0.01111105, -0.00994223,  0.02028815, -0.0497045 ],\n",
       "       [ 0.02113768, -0.00787457, -0.01122408,  0.01688968, -0.04486213],\n",
       "       [ 0.02516601, -0.00884441, -0.00786591,  0.02037653, -0.05124563],\n",
       "       [ 0.02472802, -0.00955927, -0.01218047,  0.01999038, -0.04771683],\n",
       "       [ 0.02170156, -0.01055751, -0.00814589,  0.02068564, -0.04696228],\n",
       "       [ 0.02485898, -0.00959709, -0.01033488,  0.02268194, -0.04605222],\n",
       "       [ 0.0183062 , -0.00955733, -0.0109983 ,  0.02188222, -0.04611121],\n",
       "       [ 0.02192404, -0.00533727, -0.01184646,  0.02040888, -0.05127967],\n",
       "       [ 0.01676567, -0.0093044 , -0.00847249,  0.01859773, -0.04900726],\n",
       "       [ 0.01906576, -0.00916026, -0.01289325,  0.01671468, -0.0494087 ],\n",
       "       [ 0.02276972, -0.01258149, -0.00977554,  0.01767718, -0.04816681],\n",
       "       [ 0.02338938, -0.01052973, -0.00933699,  0.01867436, -0.04498473],\n",
       "       [ 0.02327088, -0.00640566, -0.00740292,  0.01817292, -0.04497924],\n",
       "       [ 0.02504292, -0.00687183, -0.00896837,  0.02292903, -0.04848764],\n",
       "       [ 0.01700381, -0.01181023, -0.00892185,  0.02081809, -0.04851369],\n",
       "       [ 0.01958538, -0.0097065 , -0.00835114,  0.02106581, -0.05052281],\n",
       "       [ 0.01962392, -0.01227872, -0.00732455,  0.01768917, -0.04889262],\n",
       "       [ 0.01991236, -0.00609358, -0.0111012 ,  0.01899709, -0.05253172],\n",
       "       [ 0.02076414, -0.00898344, -0.0078576 ,  0.02114345, -0.04701249],\n",
       "       [ 0.01919619, -0.0077062 , -0.01002525,  0.02334125, -0.05039874],\n",
       "       [ 0.01689182, -0.01669576, -0.00501372,  0.02126045, -0.0494247 ],\n",
       "       [ 0.01680914, -0.00741786, -0.00922249,  0.02112301, -0.05137912],\n",
       "       [ 0.02039813, -0.01346888, -0.00919998,  0.0189424 , -0.04858908]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab, num_frame = io_funcs.load_binary_file_frame(synth_dur_lab_norm_file_list[0], 368)\n",
    "lab = torch.from_numpy(lab)\n",
    "lab = lab[None, :, :]\n",
    "dur_cmp_pred = synth_duration_model(lab)\n",
    "dur_cmp_pred = dur_cmp_pred.detach().numpy()[0]\n",
    "dur_cmp_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/inter/dur_cmp_pred/nitech_jp_song070_f001_070.cmp\n",
      "[ 5.4560676 16.22251   14.50423    9.729328   5.6103916]\n",
      "[ 4.778163  32.451237  30.338848  25.81974    6.8933287]\n"
     ]
    }
   ],
   "source": [
    "fid = open(dur_cmp_norm_file, 'rb')\n",
    "dur_cmp_norm_info = np.fromfile(fid, dtype=np.float32)\n",
    "fid.close()\n",
    "dur_cmp_norm_info = dur_cmp_norm_info.reshape(2, -1)\n",
    "dur_cmp_mean = dur_cmp_norm_info[0, ]\n",
    "dur_cmp_std = dur_cmp_norm_info[1, ]\n",
    "\n",
    "print(synth_dur_cmp_pred_file_list[0])\n",
    "\n",
    "io_funcs.array_to_binary_file(dur_cmp_pred, synth_dur_cmp_pred_file_list[0])\n",
    "\n",
    "print(dur_cmp_mean)\n",
    "print(dur_cmp_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.551061  15.752278  14.200991  10.206416   5.2901797]\n",
      " [ 5.5533843 15.87799   14.0966015 10.179635   5.295764 ]\n",
      " [ 5.550715  15.884184  14.2144    10.24537    5.2878685]\n",
      " [ 5.5525837 15.890511  14.132585  10.232053   5.256593 ]\n",
      " [ 5.543806  15.852673  14.130717  10.249583   5.27523  ]\n",
      " [ 5.546036  15.958624  14.043604  10.331711   5.2914195]\n",
      " [ 5.55692   16.027588  14.147421  10.241272   5.3083267]\n",
      " [ 5.5535684 15.856915  14.245941  10.315426   5.292195 ]\n",
      " [ 5.5677176 15.877155  14.226478  10.230915   5.242901 ]\n",
      " [ 5.556892  15.876377  14.209519  10.219336   5.262225 ]]\n"
     ]
    }
   ],
   "source": [
    "synth_dur_denormaliser = MeanVarianceNorm(feature_dimension=dur_cmp_dim)\n",
    "synth_dur_denormaliser.feature_denormalisation(synth_dur_cmp_pred_file_list, synth_dur_cmp_pred_file_list, dur_cmp_mean, dur_cmp_std)\n",
    "dur_cmp_pred, _ = io_funcs.load_binary_file_frame(synth_dur_cmp_pred_file_list[0], 5)\n",
    "print(dur_cmp_pred[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change original label files with newly predicted durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/inter/dur_cmp_pred/nitech_jp_song070_f001_070.dur']\n",
      "['/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/inter/dur_cmp_pred/nitech_jp_song070_f001_070.lab']\n"
     ]
    }
   ],
   "source": [
    "from frontend.parameter_generation import ParameterGeneration\n",
    "from frontend.label_modifier import HTSLabelModification\n",
    "synth_dur_extention_dict = {'dur': '.dur'}\n",
    "synth_dur_out_dimension_dict = {'dur': 5}\n",
    "synth_dur_cmp_dim = 5\n",
    "\n",
    "\n",
    "synth_dur_list = [os.path.splitext(synth_dur_cmp_pred_file_list[0])[0] + synth_dur_extention_dict['dur']]\n",
    "synth_lab_list = [os.path.splitext(synth_dur_cmp_pred_file_list[0])[0] + '.lab']\n",
    "print(synth_dur_list)\n",
    "print(synth_lab_list)\n",
    "\n",
    "synth_decomposer = ParameterGeneration(['mgc', 'bap', 'lf0'])\n",
    "synth_decomposer.duration_decomposition(synth_dur_cmp_pred_file_list, synth_dur_cmp_dim, synth_dur_out_dimension_dict, synth_dur_extention_dict)\n",
    "synth_label_modifier = HTSLabelModification(silence_pattern = silence_pattern)\n",
    "synth_label_modifier.modify_duration_labels(input_lab_file_list, synth_dur_list, synth_lab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize label files for acoustic model (silence not removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_acou_lab_normaliser = HTSLabelNormalisation(question, add_frame_features=True, subphone_feats='full')\n",
    "synth_acou_lab_normaliser.perform_normalisation(synth_lab_list, synth_acou_lab_file_list)\n",
    "synth_acou_lab_normaliser = MinMaxNormalisation(feature_dimension = acou_lab_dim, min_value = 0.01, max_value = 0.99)\n",
    "synth_acou_lab_normaliser.load_min_max_values(acou_lab_norm_file)\n",
    "synth_acou_lab_normaliser.normalise_data(synth_acou_lab_file_list, synth_acou_lab_norm_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict acoustic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DurationModel:\n\tMissing key(s) in state_dict: \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\", \"fc4.weight\", \"fc4.bias\", \"fc5.weight\", \"fc5.bias\". \n\tUnexpected key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-70ce31ce40c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msynth_acoustic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDurationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macou_lab_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macou_cmp_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msynth_acoustic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macou_nn_mdl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msynth_acoustic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DurationModel:\n\tMissing key(s) in state_dict: \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\", \"fc4.weight\", \"fc4.bias\", \"fc5.weight\", \"fc5.bias\". \n\tUnexpected key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\". "
     ]
    }
   ],
   "source": [
    "synth_acoustic_model = DurationModel(acou_lab_dim, acou_cmp_dim)\n",
    "synth_acoustic_model.load_state_dict(torch.load(acou_nn_mdl_file))\n",
    "synth_acoustic_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3216, 187)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab, num_frame = io_funcs.load_binary_file_frame(synth_acou_lab_norm_file_list[0], 377)\n",
    "lab = torch.from_numpy(lab)\n",
    "lab = lab[None, :, :]\n",
    "acou_cmp_pred = synth_acoustic_model(lab)\n",
    "acou_cmp_pred = acou_cmp_pred.detach().numpy()[0]\n",
    "acou_cmp_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/inter/acou_cmp_pred/nitech_jp_song070_f001_070.cmp\n",
      "[-1.33646011e+01 -1.90148572e-03  4.75082546e-04  5.96542645e+00 -3.50371033e-06 -1.21180547e-05  5.07352877e+00  1.88283157e+00 -2.73135006e-01  1.37185544e-01 -4.23395693e-01  2.41781697e-01 -2.04522818e-01 -4.18005884e-02  3.96365196e-01 -1.26078025e-01  3.74176562e-01 -1.93812922e-01 -3.76398936e-02 -1.38404528e-02 -5.09452028e-03  1.28273636e-01 -1.30870998e-01  8.73090476e-02 -2.49601901e-03 -8.83054454e-03 -3.25787514e-02 -2.69498564e-02  2.26364378e-02 -5.02169877e-02  4.38574776e-02 -4.56125587e-02  2.92196702e-02 -3.07271220e-02  2.09769118e-03  2.67485492e-02 -4.82758544e-02  5.80238625e-02 -5.66445962e-02  4.08596694e-02 -1.98573247e-02  4.57508303e-03 -4.61094460e-04 -1.20418239e-03  1.06062898e-02 -2.40169801e-02  2.86857504e-02 -2.29858626e-02  1.30661651e-02 -4.51678643e-03 -4.03065840e-03  1.32622905e-02 -2.11629681e-02  2.48682052e-02 -1.93230826e-02  8.35328922e-03  2.99246400e-03 -5.26264030e-03  2.37871916e-03  4.83263703e-03 -7.48290401e-03  8.38070177e-03 -5.56744961e-03  5.58886351e-03 -5.19738067e-03  5.24853682e-03  9.39571648e-04  8.44951021e-04  1.61141670e-05 -2.41569942e-04 -2.26512842e-04 -2.17061228e-04 -2.52631726e-04 -1.18810829e-04  4.92765830e-05 -9.69187167e-05  3.09795032e-05 -1.54342255e-04 -3.72998124e-06  3.95451389e-06 -2.83918398e-05 -7.97869961e-06 -2.04145599e-05  2.54602801e-05  2.34525887e-05 -9.76238789e-06  3.25788242e-05  1.53196343e-05  2.32092279e-05  1.94366548e-05  1.79972994e-05  3.23178028e-06  3.07410482e-05 -1.21219982e-05 -6.16994294e-06  1.00928828e-05 -2.89393870e-06  6.83943654e-06 -6.11672067e-06  5.28538931e-06 -6.64820755e-06  2.78131415e-06  2.76579794e-06 -2.92234540e-06  2.87460489e-06 -6.22570406e-06  8.65893526e-06 -4.74401804e-06  3.75802983e-07  1.40423765e-06 -4.98241434e-07  1.17370178e-06 -4.67765130e-06  3.11781787e-06  5.20443962e-07 -6.52864082e-06  3.79428457e-06 -2.07191465e-06 -2.35974994e-06  6.47399645e-08 -1.54142924e-06  1.00479696e-07 -1.84753651e-06  8.33545002e-08  5.58115858e-07 -1.35463813e-06 -3.68580106e-04 -2.90173281e-04  5.20442882e-06  6.19480634e-05  4.53602770e-05 -5.81086988e-06  2.64733972e-05  3.59655169e-05 -4.42786804e-05  3.35612935e-06 -7.97545908e-06  4.47786770e-05 -1.33591839e-05  6.83167491e-06  2.36693922e-05  2.41776479e-06 -1.25154361e-06  3.35961818e-06  9.14512384e-06 -6.72206443e-06 -3.15925490e-06 -7.43154123e-06 -5.66276776e-06  1.75299715e-06 -3.28285296e-06  3.49531706e-06 -1.22088277e-05  3.02858348e-06  2.65761514e-06 -6.95959034e-06  3.91838284e-06 -8.41016913e-07  2.09679388e-06 -3.56328155e-06  1.58765488e-06 -1.38214284e-06  3.38836139e-06 -7.08939012e-07 -3.44994055e-06  2.52165660e-06  3.31361832e-07  8.61366729e-08 -9.85291535e-07 -1.81131497e-07  3.09651000e-06 -4.15464456e-06  1.16001195e-06  1.19295214e-06 -1.89193440e-06 -1.11387317e-06  3.74759247e-06 -4.09929044e-06  2.32599882e-06  6.09038864e-08 -8.15032138e-07 -4.41149872e-08  1.26465568e-06 -7.06078254e-07  1.45156251e-08  4.09283984e-07  8.69738579e-01]\n",
      "[9.412413   1.8012996  4.208716   0.22775437 0.02732092 0.06407295 1.5248871  0.86403745 0.74400973 0.59257406 0.4841286  0.3923912  0.30851033 0.28519675 0.36933756 0.41165707 0.32822326 0.28492895 0.29147884 0.25433478 0.20159926 0.19080894 0.15436257 0.19601114 0.19408262 0.2105544  0.14320897 0.11563111 0.09560336 0.10722646 0.11261903 0.15451424 0.13682862 0.14987114 0.14291312 0.10829363 0.10096107 0.0889494  0.07560817 0.07302475 0.08292949 0.09943618 0.1028903  0.09976558 0.10206005 0.10056029 0.08708021 0.07575486 0.06951946 0.06276173 0.05988566 0.06239593 0.06657607 0.06998015 0.07346546 0.07865112 0.08020094 0.07525863 0.06977282 0.06375562 0.05756272 0.05088478 0.04439725 0.04177266 0.04052918 0.04215691 0.23098677 0.14314069 0.10022262 0.07618567 0.07058521 0.06608377 0.06079415 0.05678634 0.06002548 0.07100924 0.0704289  0.05589593 0.05586179 0.05853933 0.04358428 0.0472016  0.03954647 0.04424097 0.04026958 0.04325016 0.03644021 0.03594404 0.03191633 0.03178075 0.03469878 0.03385955 0.03373558 0.03623361 0.0301153  0.02994606 0.02777007 0.0260447  0.02510259 0.02616375 0.02751757 0.02628847 0.02835548 0.02947895 0.0264891  0.0262272  0.02554259 0.02352404 0.02176763 0.0209435  0.02154545 0.02271469 0.02250564 0.02155565 0.02238389 0.02391988 0.02306413 0.02131459 0.02075475 0.02011121 0.01887289 0.01774064 0.01678979 0.01628225 0.01628126 0.01684994 0.28003797 0.23980382 0.1709194  0.14593449 0.12961878 0.126744   0.11563729 0.11031958 0.11288798 0.13689955 0.14123376 0.11372157 0.11102027 0.12029053 0.08935279 0.09838665 0.08014144 0.09045165 0.07751207 0.08665168 0.07314873 0.07684392 0.0686731  0.06653555 0.07056335 0.066424   0.06465922 0.07008776 0.05870239 0.06021639 0.0580417  0.05520671 0.05401498 0.05576374 0.05579863 0.05131929 0.05433712 0.05449566 0.04867448 0.05036331 0.05040244 0.04769661 0.04553442 0.04481848 0.04598135 0.0468513  0.04461323 0.04208625 0.04389333 0.04569512 0.04256402 0.03959534 0.03996718 0.03983006 0.03839369 0.03716945 0.03606939 0.03533025 0.03562297 0.0364862  0.33659083]\n"
     ]
    }
   ],
   "source": [
    "fid = open(acou_cmp_norm_file, 'rb')\n",
    "acou_cmp_norm_info = np.fromfile(fid, dtype=np.float32)\n",
    "fid.close()\n",
    "acou_cmp_norm_info = acou_cmp_norm_info.reshape(2, -1)\n",
    "acou_cmp_mean = acou_cmp_norm_info[0, ]\n",
    "acou_cmp_std = acou_cmp_norm_info[1, ]\n",
    "\n",
    "print(synth_acou_cmp_pred_file_list[0])\n",
    "\n",
    "\n",
    "io_funcs.array_to_binary_file(acou_cmp_pred, synth_acou_cmp_pred_file_list[0])\n",
    "\n",
    "print(acou_cmp_mean)\n",
    "print(acou_cmp_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38575516e+01  1.01585373e-01 -5.46068065e-02  5.96189833e+00  6.89454260e-04 -2.46225647e-03  5.09212208e+00  1.87044120e+00 -2.88518071e-01  1.22004353e-01]\n",
      " [-1.38563013e+01  1.00108132e-01 -5.43414243e-02  5.96184349e+00  6.82886865e-04 -2.47346167e-03  5.09386969e+00  1.86894822e+00 -2.89718211e-01  1.22529343e-01]\n",
      " [-1.38563023e+01  1.00061432e-01 -5.43866716e-02  5.96184492e+00  6.82633079e-04 -2.47423304e-03  5.09383392e+00  1.86895490e+00 -2.89702773e-01  1.22511789e-01]\n",
      " [-1.38563204e+01  1.00020953e-01 -5.44308163e-02  5.96184683e+00  6.82366954e-04 -2.47490872e-03  5.09380102e+00  1.86896157e+00 -2.89689153e-01  1.22494146e-01]\n",
      " [-1.38563423e+01  9.99839976e-02 -5.44703752e-02  5.96184874e+00  6.82100654e-04 -2.47563026e-03  5.09376812e+00  1.86896980e+00 -2.89676309e-01  1.22475892e-01]\n",
      " [-1.38563643e+01  9.99474004e-02 -5.45096397e-02  5.96185064e+00  6.81819394e-04 -2.47638649e-03  5.09373426e+00  1.86897981e+00 -2.89664090e-01  1.22457244e-01]\n",
      " [-1.38563890e+01  9.99107435e-02 -5.45403101e-02  5.96185207e+00  6.81546400e-04 -2.47718301e-03  5.09370041e+00  1.86898839e+00 -2.89651722e-01  1.22438923e-01]\n",
      " [-1.38564091e+01  9.98726338e-02 -5.45758195e-02  5.96185303e+00  6.81370148e-04 -2.47796741e-03  5.09366655e+00  1.86899626e+00 -2.89639503e-01  1.22421421e-01]\n",
      " [-1.38563900e+01  9.98384506e-02 -5.46084717e-02  5.96185398e+00  6.81302103e-04 -2.47862795e-03  5.09363413e+00  1.86900294e+00 -2.89627761e-01  1.22403778e-01]\n",
      " [-1.38563643e+01  9.98053476e-02 -5.46406657e-02  5.96185493e+00  6.81248843e-04 -2.47926894e-03  5.09360266e+00  1.86900938e+00 -2.89616227e-01  1.22386232e-01]]\n"
     ]
    }
   ],
   "source": [
    "synth_acou_denormaliser = MeanVarianceNorm(feature_dimension=acou_cmp_dim)\n",
    "synth_acou_denormaliser.feature_denormalisation(synth_acou_cmp_pred_file_list, synth_acou_cmp_pred_file_list, acou_cmp_mean, acou_cmp_std)\n",
    "dur_cmp_pred, _ = io_funcs.load_binary_file_frame(synth_acou_cmp_pred_file_list[0], 187)\n",
    "print(dur_cmp_pred[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_acou_extention_dict = {'lf0': '.lf0', 'mgc': '.mgc', 'bap': '.bap'}\n",
    "synth_acou_out_dimension_dict = {'lf0': 3, 'mgc': 180, 'bap': 3, 'vuv': 1}\n",
    "synth_acou_cmp_dim = 187\n",
    "\n",
    "\n",
    "# synth_dur_list = [os.path.splitext(synth_dur_cmp_pred_file_list[0])[0] + synth_dur_extention_dict['dur']]\n",
    "# synth_lab_list = [os.path.splitext(synth_dur_cmp_pred_file_list[0])[0] + '.lab']\n",
    "# print(synth_dur_list)\n",
    "# print(synth_lab_list)\n",
    "\n",
    "synth_decomposer = ParameterGeneration(['mgc', 'bap', 'lf0'])\n",
    "\n",
    "synth_decomposer.acoustic_decomposition(synth_acou_cmp_pred_file_list, synth_acou_cmp_dim, synth_acou_out_dimension_dict, synth_acou_extention_dict, acou_variance_file_dict,True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy features to wav\n",
    "for file in synth_acou_cmp_pred_file_list:\n",
    "    base = os.path.splitext(file)[0]\n",
    "    for ext in (['.mgc', '.bap', '.lf0']):\n",
    "        feat_file = base + ext\n",
    "        copy(feat_file, wav_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(args,log=True):\n",
    "    logger = logging.getLogger(\"subprocess\")\n",
    "\n",
    "    # a convenience function instead of calling subprocess directly\n",
    "    # this is so that we can do some logging and catch exceptions\n",
    "\n",
    "    # we don't always want debug logging, even when logging level is DEBUG\n",
    "    # especially if calling a lot of external functions\n",
    "    # so we can disable it by force, where necessary\n",
    "    if log:\n",
    "        logger.debug('%s' % args)\n",
    "\n",
    "    try:\n",
    "        # the following is only available in later versions of Python\n",
    "        # rval = subprocess.check_output(args)\n",
    "\n",
    "        # bufsize=-1 enables buffering and may improve performance compared to the unbuffered case\n",
    "        p = subprocess.Popen(args, bufsize=-1, shell=True,\n",
    "                        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                        close_fds=True, env=os.environ)\n",
    "        # better to use communicate() than read() and write() - this avoids deadlocks\n",
    "        (stdoutdata, stderrdata) = p.communicate()\n",
    "\n",
    "        if p.returncode != 0:\n",
    "            # for critical things, we always log, even if log==False\n",
    "            logger.critical('exit status %d' % p.returncode )\n",
    "            logger.critical(' for command: %s' % args )\n",
    "            logger.critical('      stderr: %s' % stderrdata )\n",
    "            logger.critical('      stdout: %s' % stdoutdata )\n",
    "            raise OSError\n",
    "\n",
    "        return (stdoutdata, stderrdata)\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # not sure under what circumstances this exception would be raised in Python 2.6\n",
    "        logger.critical('exit status %d' % e.returncode )\n",
    "        logger.critical(' for command: %s' % args )\n",
    "        # not sure if there is an 'output' attribute under 2.6 ? still need to test this...\n",
    "        logger.critical('  output: %s' % e.output )\n",
    "        raise\n",
    "\n",
    "    except ValueError:\n",
    "        logger.critical('ValueError for %s' % args )\n",
    "        raise\n",
    "\n",
    "    except OSError:\n",
    "        logger.critical('OSError for %s' % args )\n",
    "        raise\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logger.critical('KeyboardInterrupt during %s' % args )\n",
    "        try:\n",
    "            # try to kill the subprocess, if it exists\n",
    "            p.kill()\n",
    "        except UnboundLocalError:\n",
    "            # this means that p was undefined at the moment of the keyboard interrupt\n",
    "            # (and we do nothing)\n",
    "            pass\n",
    "\n",
    "        raise KeyboardInterrupt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/test/cfg.pkl', 'rb') as f:\n",
    "    cfg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavgen_straight_type_vocoder(gen_dir, file_id_list, logger):\n",
    "    '''\n",
    "    Waveform generation with STRAIGHT or WORLD vocoders.\n",
    "    (whose acoustic parameters are: mgc, bap, and lf0)\n",
    "    '''\n",
    "\n",
    "    pf_coef = 1.4\n",
    "    fw_coef = 0.58\n",
    "    co_coef = 511\n",
    "    fl_coef = 1024\n",
    "    mgc_dim = 60\n",
    "    fw_alpha = 0.58\n",
    "    sr = 16000\n",
    "    fl = 1024\n",
    "\n",
    "\n",
    "\n",
    "    counter=1\n",
    "    max_counter = len(file_id_list)\n",
    "\n",
    "\n",
    "    for filename in file_id_list:\n",
    "\n",
    "        logger.info('creating waveform for %4d of %4d: %s' % (counter,max_counter,filename) )\n",
    "        counter=counter+1\n",
    "        base   = filename\n",
    "        files = {'sp'  : base + '.sp',\n",
    "                 'mgc' : base + '.mgc',\n",
    "                 'f0'  : base + '.f0',\n",
    "                 'lf0' : base + '.lf0',\n",
    "                 'ap'  : base + '.ap',\n",
    "                 'bap' : base + '.bap',\n",
    "                 'wav' : base + '.wav'}\n",
    "\n",
    "        mgc_file_name = files['mgc']\n",
    "        bap_file_name = files['bap']\n",
    "\n",
    "        cur_dir = os.getcwd()\n",
    "        os.chdir(gen_dir)\n",
    "\n",
    "\n",
    "        mgc_file_name = files['mgc']+'_p_mgc'\n",
    "        post_filter(files['mgc'], mgc_file_name, mgc_dim, pf_coef, fw_coef, co_coef, fl_coef, gen_dir, SPTK)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        run_process('{sopr} -magic -1.0E+10 -EXP -MAGIC 0.0 {lf0} | {x2x} +fd > {f0}'.format(sopr=SPTK['SOPR'], lf0=files['lf0'], x2x=SPTK['X2X'], f0=files['f0']))\n",
    "\n",
    "        run_process('{sopr} -c 0 {bap} | {x2x} +fd > {ap}'.format(sopr=SPTK['SOPR'],bap=files['bap'],x2x=SPTK['X2X'],ap=files['ap']))\n",
    "\n",
    "\n",
    "        run_process('{mgc2sp} -a {alpha} -g 0 -m {order} -l {fl} -o 2 {mgc} | {sopr} -d 32768.0 -P | {x2x} +fd > {sp}'\n",
    "                        .format(mgc2sp=SPTK['MGC2SP'], alpha=fw_alpha, order=mgc_dim-1, fl=fl, mgc=mgc_file_name, sopr=SPTK['SOPR'], x2x=SPTK['X2X'], sp=files['sp']))\n",
    "\n",
    "        run_process('{synworld} {fl} {sr} {f0} {sp} {ap} {wav}'\n",
    "                         .format(synworld=WORLD['SYNTHESIS'], fl=fl, sr=sr, f0=files['f0'], sp=files['sp'], ap=files['ap'], wav=files['wav']))\n",
    "\n",
    "#         run_process('rm -f {ap} {sp} {f0}'.format(ap=files['ap'],sp=files['sp'],f0=files['f0']))\n",
    "\n",
    "        os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_filter(mgc_file_in, mgc_file_out, mgc_dim, pf_coef, fw_coef, co_coef, fl_coef, gen_dir, SPTK):\n",
    "\n",
    "\n",
    "    line = \"echo 1 1 \"\n",
    "    for i in range(2, mgc_dim):\n",
    "        line = line + str(pf_coef) + \" \"\n",
    "\n",
    "    run_process('{line} | {x2x} +af > {weight}'\n",
    "                .format(line=line, x2x=SPTK['X2X'], weight=os.path.join(gen_dir, 'weight')))\n",
    "\n",
    "    run_process('{freqt} -m {order} -a {fw} -M {co} -A 0 < {mgc} | {c2acr} -m {co} -M 0 -l {fl} > {base_r0}'\n",
    "                .format(freqt=SPTK['FREQT'], order=mgc_dim-1, fw=fw_coef, co=co_coef, mgc=mgc_file_in, c2acr=SPTK['C2ACR'], fl=fl_coef, base_r0=mgc_file_in+'_r0'))\n",
    "\n",
    "    run_process('{vopr} -m -n {order} < {mgc} {weight} | {freqt} -m {order} -a {fw} -M {co} -A 0 | {c2acr} -m {co} -M 0 -l {fl} > {base_p_r0}'\n",
    "                .format(vopr=SPTK['VOPR'], order=mgc_dim-1, mgc=mgc_file_in, weight=os.path.join(gen_dir, 'weight'),\n",
    "                        freqt=SPTK['FREQT'], fw=fw_coef, co=co_coef,\n",
    "                        c2acr=SPTK['C2ACR'], fl=fl_coef, base_p_r0=mgc_file_in+'_p_r0'))\n",
    "\n",
    "    run_process('{vopr} -m -n {order} < {mgc} {weight} | {mc2b} -m {order} -a {fw} | {bcp} -n {order} -s 0 -e 0 > {base_b0}'\n",
    "                .format(vopr=SPTK['VOPR'], order=mgc_dim-1, mgc=mgc_file_in, weight=os.path.join(gen_dir, 'weight'),\n",
    "                        mc2b=SPTK['MC2B'], fw=fw_coef,\n",
    "                        bcp=SPTK['BCP'], base_b0=mgc_file_in+'_b0'))\n",
    "\n",
    "    run_process('{vopr} -d < {base_r0} {base_p_r0} | {sopr} -LN -d 2 | {vopr} -a {base_b0} > {base_p_b0}'\n",
    "                .format(vopr=SPTK['VOPR'], base_r0=mgc_file_in+'_r0', base_p_r0=mgc_file_in+'_p_r0',\n",
    "                        sopr=SPTK['SOPR'],\n",
    "                        base_b0=mgc_file_in+'_b0', base_p_b0=mgc_file_in+'_p_b0'))\n",
    "\n",
    "    run_process('{vopr} -m -n {order} < {mgc} {weight} | {mc2b} -m {order} -a {fw} | {bcp} -n {order} -s 1 -e {order} | {merge} -n {order2} -s 0 -N 0 {base_p_b0} | {b2mc} -m {order} -a {fw} > {base_p_mgc}'\n",
    "                .format(vopr=SPTK['VOPR'], order=mgc_dim-1, mgc=mgc_file_in, weight=os.path.join(gen_dir, 'weight'),\n",
    "                        mc2b=SPTK['MC2B'],  fw=fw_coef,\n",
    "                        bcp=SPTK['BCP'],\n",
    "                        merge=SPTK['MERGE'], order2=mgc_dim-2, base_p_b0=mgc_file_in+'_p_b0',\n",
    "                        b2mc=SPTK['B2MC'], base_p_mgc=mgc_file_out))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy features to wav\n",
    "for file in synth_acou_cmp_pred_file_list:\n",
    "    base = os.path.splitext(file)[0]\n",
    "    for ext in (['.mgc', '.bap', '.lf0']):\n",
    "        feat_file = base + ext\n",
    "        copy(feat_file, wav_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/wav\n",
      "['nitech_jp_song070_f001_070']\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(\"wav_generation\")\n",
    "wavgen_straight_type_vocoder(wav_dir, synth_id_list, logger)\n",
    "print(wav_dir)\n",
    "print(synth_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "my_cmp_norm_info_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/acoustic_model/inter/cmp_norm_187.dat'\n",
    "ml_cmp_norm_info_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s1/experiments/acoustic_model/inter_module/norm_info__mgc_lf0_vuv_bap_187_MVN.dat'\n",
    "\n",
    "fid = open(my_cmp_norm_info_file, 'rb')\n",
    "my_cmp_norm_info = np.fromfile(fid, dtype=np.float32)\n",
    "fid.close()\n",
    "my_cmp_norm_info = my_cmp_norm_info.reshape(2, -1)\n",
    "my_cmp_mean = my_cmp_norm_info[0, ]\n",
    "my_cmp_std = my_cmp_norm_info[1, ]\n",
    "\n",
    "fid = open(ml_cmp_norm_info_file, 'rb')\n",
    "ml_cmp_norm_info = np.fromfile(fid, dtype=np.float32)\n",
    "fid.close()\n",
    "ml_cmp_norm_info = ml_cmp_norm_info.reshape(2, -1)\n",
    "ml_cmp_mean = ml_cmp_norm_info[0, ]\n",
    "ml_cmp_std = ml_cmp_norm_info[1, ]\n",
    "\n",
    "print(my_cmp_mean.all() == ml_cmp_mean.all())\n",
    "print(my_cmp_std.all() == ml_cmp_std.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "my_cmp_no_silence_norm_file = acou_cmp_no_silence_norm_file_list[0]\n",
    "ml_cmp_no_silence_norm_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s1/experiments/acoustic_model/inter_module/nn_norm_mgc_lf0_vuv_bap_187/nitech_jp_song070_f001_003.cmp'\n",
    "my_cmp_no_silence_norm, my_n_frame = io_funcs.load_binary_file_frame(my_cmp_no_silence_norm_file, 187)\n",
    "ml_cmp_no_silence_norm, ml_n_frame = io_funcs.load_binary_file_frame(ml_cmp_no_silence_norm_file, 187)\n",
    "print(my_n_frame == ml_n_frame)\n",
    "print(my_cmp_no_silence_norm.all() == ml_cmp_no_silence_norm.all())\n",
    "\n",
    "my_lab_no_silence_norm_file = acou_lab_no_silence_norm_file_list[0]\n",
    "ml_lab_no_silence_norm_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s1/experiments/acoustic_model/inter_module/nn_no_silence_lab_norm_377/nitech_jp_song070_f001_003.lab'\n",
    "my_lab_no_silence_norm, my_n_frame = io_funcs.load_binary_file_frame(my_lab_no_silence_norm_file, 377)\n",
    "ml_lab_no_silence_norm, ml_n_frame = io_funcs.load_binary_file_frame(ml_lab_no_silence_norm_file, 377)\n",
    "print(my_n_frame == ml_n_frame)\n",
    "print(my_lab_no_silence_norm.all() == ml_lab_no_silence_norm.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cmp_no_silence_norm_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/acoustic_model/inter/cmp_no_silence_norm_187/nitech_jp_song070_f001_003.cmp'\n",
    "test_cmp_file_list = [test_cmp_no_silence_norm_file]\n",
    "test_cmp_no_silence_pred_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/test/nitech_jp_song070_f001_003.cmp'\n",
    "test_denorm_file_list = [test_cmp_no_silence_pred_file]\n",
    "\n",
    "synth_acou_denormaliser = MeanVarianceNorm(feature_dimension=acou_cmp_dim)\n",
    "synth_acou_denormaliser.feature_denormalisation(test_cmp_file_list, test_denorm_file_list, acou_cmp_mean, acou_cmp_std)\n",
    "\n",
    "synth_decomposer.acoustic_decomposition(test_denorm_file_list, synth_acou_cmp_dim, synth_acou_out_dimension_dict, synth_acou_extention_dict, acou_variance_file_dict,True)\n",
    "wavgen_straight_type_vocoder('/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/test/', ['nitech_jp_song070_f001_003'], logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_file = os.path.join(wav_dir, 'nitech_jp_song070_f001_070.f0')\n",
    "mgc_file = '/home/yongliang/third_party/merlin/egs/singing_synthesis/s3/exp/synth/inter/acou_cmp_pred/nitech_jp_song070_f001_070.mgc'\n",
    "f0, n_frame = io_funcs.load_binary_file_frame(f0_file, 1)\n",
    "mgc, n_frame2 = io_funcs.load_binary_file_frame(mgc_file, 60)\n",
    "print(n_frame)\n",
    "print(n_frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PITCH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
